{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5de7e8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Separate Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572e2b3d-dda8-48f6-b511-164eb0fe195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# #TODO: change FOLDER_NAME and NUM_FOLDERS\n",
    "# FOLDER_NAME = '11--Meeting'\n",
    "# SOURCE_PATH = os.path.join(os.getcwd(), 'images', FOLDER_NAME)\n",
    "# NUM_FOLDERS = 3\n",
    "\n",
    "# for index, path in enumerate(glob.glob(os.path.join(SOURCE_PATH, '*.jpg'))):\n",
    "#     #compute folder\n",
    "#     folder_index = index % NUM_FOLDERS\n",
    "    \n",
    "#     #create folder\n",
    "#     DESTINATION_PATH = os.path.join(os.getcwd(), 'images', FOLDER_NAME + '_' + str(folder_index))\n",
    "#     if not os.path.exists(DESTINATION_PATH):\n",
    "#         os.mkdir(DESTINATION_PATH)\n",
    "    \n",
    "#     file = os.path.basename(path) #extract file name\n",
    "#     source = os.path.join(SOURCE_PATH, file) # source + file name\n",
    "#     destination =  os.path.join(DESTINATION_PATH, file) # destination + file name\n",
    "    \n",
    "#     os.rename(source, destination) #move images to the destination folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c8fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import gdown\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "#libraries for yolo\n",
    "from pytorchyolo.models import load_model\n",
    "from pytorchyolo.utils.transforms import Resize, DEFAULT_TRANSFORMS\n",
    "from pytorchyolo.utils.utils import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd6df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weights():\n",
    "    model_file=[\n",
    "        'yolo_face_sthanhng.weights',\n",
    "        'yolo_face_sthanhng.cfg'\n",
    "    ]\n",
    "    \n",
    "    gdrive_url=[\n",
    "        'https://drive.google.com/uc?id=1utquM5TAnfIa1Aq0X9fCvrllHiTWazdD',\n",
    "        'https://drive.google.com/uc?id=1CPUZlYL5ik4d9y6oCyzi0930KgzawI6V'\n",
    "    ]\n",
    "    \n",
    "    cwd=os.getcwd() \n",
    "    if 'weights' in os.listdir(cwd):\n",
    "        for i in range(len(model_file)):\n",
    "            if model_file[i] in os.listdir(os.path.join(cwd, 'weights')):\n",
    "                print(model_file[i] + ':: status : file already exists')\n",
    "            else:\n",
    "                gdown.download(gdrive_url[i],os.path.join(cwd, 'weights', model_file[i]), quiet=False)\n",
    "    else:\n",
    "        os.makedirs(os.path.join(cwd,'weights'))\n",
    "        for i in range(len(model_file)):\n",
    "            gdown.download(gdrive_url[i], os.path.join(cwd, 'weights', model_file[i]), quiet=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847df66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo_face_sthanhng.weights:: status : file already exists\n",
      "yolo_face_sthanhng.cfg:: status : file already exists\n"
     ]
    }
   ],
   "source": [
    "# download the necessary weights for YOLO-Face\n",
    "download_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4752",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('src_release')## YOLOFace with FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4964d9-d8a9-421d-8111-12d51ab2218d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# YOLO Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a22160e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_0): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_1): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_3): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (shortcut_4): Sequential()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_6): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_7): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (shortcut_8): Sequential()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_9): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_10): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (shortcut_11): Sequential()\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_12): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_13): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_14): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (15): Sequential(\n",
       "      (shortcut_15): Sequential()\n",
       "    )\n",
       "    (16): Sequential(\n",
       "      (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_16): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (17): Sequential(\n",
       "      (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_17): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (18): Sequential(\n",
       "      (shortcut_18): Sequential()\n",
       "    )\n",
       "    (19): Sequential(\n",
       "      (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_19): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (20): Sequential(\n",
       "      (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_20): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (21): Sequential(\n",
       "      (shortcut_21): Sequential()\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_22): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (23): Sequential(\n",
       "      (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_23): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (24): Sequential(\n",
       "      (shortcut_24): Sequential()\n",
       "    )\n",
       "    (25): Sequential(\n",
       "      (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_25): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_26): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (27): Sequential(\n",
       "      (shortcut_27): Sequential()\n",
       "    )\n",
       "    (28): Sequential(\n",
       "      (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_28): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_29): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (30): Sequential(\n",
       "      (shortcut_30): Sequential()\n",
       "    )\n",
       "    (31): Sequential(\n",
       "      (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_31): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_32): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (33): Sequential(\n",
       "      (shortcut_33): Sequential()\n",
       "    )\n",
       "    (34): Sequential(\n",
       "      (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_34): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (35): Sequential(\n",
       "      (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_35): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (36): Sequential(\n",
       "      (shortcut_36): Sequential()\n",
       "    )\n",
       "    (37): Sequential(\n",
       "      (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_37): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_38): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (39): Sequential(\n",
       "      (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_39): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (40): Sequential(\n",
       "      (shortcut_40): Sequential()\n",
       "    )\n",
       "    (41): Sequential(\n",
       "      (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_41): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (42): Sequential(\n",
       "      (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_42): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (43): Sequential(\n",
       "      (shortcut_43): Sequential()\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_44): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (45): Sequential(\n",
       "      (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_45): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (46): Sequential(\n",
       "      (shortcut_46): Sequential()\n",
       "    )\n",
       "    (47): Sequential(\n",
       "      (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_47): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (48): Sequential(\n",
       "      (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_48): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (49): Sequential(\n",
       "      (shortcut_49): Sequential()\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_50): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (51): Sequential(\n",
       "      (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_51): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (52): Sequential(\n",
       "      (shortcut_52): Sequential()\n",
       "    )\n",
       "    (53): Sequential(\n",
       "      (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_53): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (54): Sequential(\n",
       "      (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_54): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (55): Sequential(\n",
       "      (shortcut_55): Sequential()\n",
       "    )\n",
       "    (56): Sequential(\n",
       "      (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_56): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (57): Sequential(\n",
       "      (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_57): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (58): Sequential(\n",
       "      (shortcut_58): Sequential()\n",
       "    )\n",
       "    (59): Sequential(\n",
       "      (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_59): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (60): Sequential(\n",
       "      (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_60): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (61): Sequential(\n",
       "      (shortcut_61): Sequential()\n",
       "    )\n",
       "    (62): Sequential(\n",
       "      (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_62): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_63): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (64): Sequential(\n",
       "      (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_64): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (65): Sequential(\n",
       "      (shortcut_65): Sequential()\n",
       "    )\n",
       "    (66): Sequential(\n",
       "      (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_66): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (67): Sequential(\n",
       "      (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_67): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (68): Sequential(\n",
       "      (shortcut_68): Sequential()\n",
       "    )\n",
       "    (69): Sequential(\n",
       "      (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_69): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (70): Sequential(\n",
       "      (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_70): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (71): Sequential(\n",
       "      (shortcut_71): Sequential()\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_72): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (73): Sequential(\n",
       "      (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_73): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (74): Sequential(\n",
       "      (shortcut_74): Sequential()\n",
       "    )\n",
       "    (75): Sequential(\n",
       "      (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_75): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (76): Sequential(\n",
       "      (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_76): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (77): Sequential(\n",
       "      (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_77): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (78): Sequential(\n",
       "      (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_78): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (79): Sequential(\n",
       "      (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_79): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (80): Sequential(\n",
       "      (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_80): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (81): Sequential(\n",
       "      (conv_81): Conv2d(1024, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (82): Sequential(\n",
       "      (yolo_82): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "    (83): Sequential(\n",
       "      (route_83): Sequential()\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_84): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (85): Sequential(\n",
       "      (upsample_85): Upsample()\n",
       "    )\n",
       "    (86): Sequential(\n",
       "      (route_86): Sequential()\n",
       "    )\n",
       "    (87): Sequential(\n",
       "      (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_87): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (88): Sequential(\n",
       "      (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_88): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (89): Sequential(\n",
       "      (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_89): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (90): Sequential(\n",
       "      (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_90): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (91): Sequential(\n",
       "      (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_91): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (92): Sequential(\n",
       "      (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_92): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (93): Sequential(\n",
       "      (conv_93): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (94): Sequential(\n",
       "      (yolo_94): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "    (95): Sequential(\n",
       "      (route_95): Sequential()\n",
       "    )\n",
       "    (96): Sequential(\n",
       "      (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_96): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (97): Sequential(\n",
       "      (upsample_97): Upsample()\n",
       "    )\n",
       "    (98): Sequential(\n",
       "      (route_98): Sequential()\n",
       "    )\n",
       "    (99): Sequential(\n",
       "      (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_99): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (100): Sequential(\n",
       "      (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_100): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (101): Sequential(\n",
       "      (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_101): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (102): Sequential(\n",
       "      (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_102): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (103): Sequential(\n",
       "      (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_103): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (104): Sequential(\n",
       "      (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leaky_104): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (105): Sequential(\n",
       "      (conv_105): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (106): Sequential(\n",
       "      (yolo_106): YOLOLayer(\n",
       "        (mse_loss): MSELoss()\n",
       "        (bce_loss): BCELoss()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patterned after FGSM tutorial (https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "device, model = load_model('./weights/yolo_face_sthanhng.cfg', \"./weights/yolo_face_sthanhng.weights\")\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c215245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_cpu(image):\n",
    "    return image.detach().cpu()\n",
    "\n",
    "# convert 1x3x416x416 to 416x416x3\n",
    "def reshape_image(image):\n",
    "    return np.transpose(np.squeeze(image), (1 ,2, 0))\n",
    "\n",
    "# convert 1x3x416x416 tensor to 416x416x3 numpy image\n",
    "def tensor_to_image(image):\n",
    "    return np.transpose(image.detach().cpu().squeeze().numpy(), (1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7c3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, device):\n",
    "    \n",
    "    df = pd.DataFrame() # dataframe storing the dataset\n",
    "    row = {} #the information/columns for a single row in the dataset is stored here\n",
    "    \n",
    "    # Loop over all examples in test set\n",
    "    for path in glob.glob(os.path.join(FOLDER_PATH, '*.jpg')):\n",
    "        \n",
    "        # GET THE FILENAME\n",
    "        filename = os.path.basename(path)\n",
    "        filename = filename.split(\".\")[0]\n",
    "        print(filename)\n",
    "        \n",
    "        # INITIALIZE A FACE COUNTER\n",
    "        face_count = 0\n",
    "        \n",
    "        row['path'] = path\n",
    "        row['source_file'] = path.split(\"\\\\\")[-1]\n",
    "        # print(path)\n",
    "        # print(row['source_file'])\n",
    "        \n",
    "        # read and transform the image from the path\n",
    "        data = cv2.imread(path)  # read the image\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "        data = transforms.Compose([DEFAULT_TRANSFORMS,Resize(416)])((data, np.zeros((1, 5))))[0].unsqueeze(0) # transform the image\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        # Forward pass the data through the model\n",
    "            output = model(data)\n",
    "        \n",
    "            # call non max suppression\n",
    "            nms, nms_output = non_max_suppression(output, 0.5, 0.5) #conf_thres and iou_thres = 0.5\n",
    "        \n",
    "        face_list = []\n",
    "        if type(nms_output[0]) is not int:\n",
    "            face_list = nms_output[0]\n",
    "        \n",
    "        # loop through each of the faces in the image\n",
    "        for face_index, face_row in enumerate(face_list): #nms_output[0] because the model is designed to take in several images at a time from the dataloader but we are only loading the image one at a time\n",
    "            # FACE_FILENAME\n",
    "            face_filename = filename + \"_\" + str(face_count)\n",
    "            row['face_index'] = face_index\n",
    "#             print('Face ', face_index)\n",
    "            \n",
    "            # get the coordinate of the face bounding box\n",
    "            #(x1, y1) upper left, (x2, y2) lower right\n",
    "            x, y, w, h = face_row[0], face_row[1], face_row[2], face_row[3]\n",
    "            \n",
    "            # cropped image with bounding box\n",
    "            # getting (x1, y1) upper left, (x2, y2) lower right\n",
    "            x1 = max(int(np.floor((x - w / 2).detach().cpu().numpy())), 0)\n",
    "            y1 = max(int(np.floor((y - h / 2).detach().cpu().numpy())), 0)\n",
    "            x2 = min(int(np.ceil((x + w / 2).detach().cpu().numpy())), 415)\n",
    "            y2 = min(int(np.ceil((y + h / 2).detach().cpu().numpy())), 415)\n",
    "            \n",
    "            row['x1'], row['y1'], row['x2'], row['y2'] = x1, y1, x2, y2\n",
    "            \n",
    "            # print('Cropped')\n",
    "            # print(x1, y1, x2, y2)\n",
    "            bbox_image = detach_cpu(data)[:, :, y1:y2, x1:x2] #get the first dimension, the channels, and crop it\n",
    "            bbox_image = tensor_to_image(bbox_image) #reshape the image to (w/h, h/w, channel)\n",
    "            bbox_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(128)])((bbox_image, np.zeros((1, 5))))[0], (1, 2, 0)).numpy() # resize image to 128x128\n",
    "            bbox_image = (bbox_image * 255).astype(np.uint8)\n",
    "#             plt.imshow(bbox_image)\n",
    "#             plt.show()\n",
    "            \n",
    "#             bbox_image = cv2.cvtColor(bbox_image, cv2.COLOR_RGB2BGR)\n",
    "#             cv2.imwrite(os.path.join(BBOX_PATH, row['source_file'] + str(face_index) + '.jpg'), bbox_image)\n",
    "            \n",
    "            # getting (x1, y1) upper left, (x2, y2) lower right\n",
    "             # cropped image with bounding box + some padding\n",
    "            x1_pad = max(int(np.floor((x - w).detach().cpu().numpy())), 0) # prevent negative values\n",
    "            y1_pad = max(int(np.floor((y - h).detach().cpu().numpy())), 0)\n",
    "            x2_pad = min(int(np.ceil((x + w).detach().cpu().numpy())), 415) # prevent from getting out of range\n",
    "            y2_pad = min(int(np.ceil((y + h).detach().cpu().numpy())), 415)\n",
    "            \n",
    "            row['x1_pad'], row['y1_pad'], row['x2_pad'], row['y2_pad'] = x1_pad, y1_pad, x2_pad, y2_pad\n",
    "            \n",
    "            pad_image = detach_cpu(data)[:, :, y1_pad:y2_pad, x1_pad:x2_pad] #get the first dimension, the channels, and crop it\n",
    "            pad_image = tensor_to_image(pad_image) #reshape the image to (w/h, h/w, channel)\n",
    "            \n",
    "            # Original Pad Size\n",
    "            # GET THE LONGEST MAX AND THEN PAD\n",
    "            greater_size = max((x2_pad - x1_pad),(y2_pad - y1_pad))\n",
    "            orig_pad_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(greater_size)])((pad_image, np.zeros((1, 5))))[0], (1, 2, 0)).numpy() # resize image to GREATER SIZE\n",
    "            orig_pad_image = (orig_pad_image * 255).astype(np.uint8)\n",
    "            orig_pad_image = cv2.cvtColor(orig_pad_image, cv2.COLOR_RGB2BGR)         \n",
    "            cv2.imwrite(os.path.join(ORIG_PAD_PATH, \"mask_\" + face_filename + \"_image_final.png\"), orig_pad_image)\n",
    "            \n",
    "            pad_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(128)])((pad_image, np.zeros((1, 5))))[0], (1, 2, 0)).numpy() # resize image to 128x128\n",
    "            pad_image = (pad_image * 255).astype(np.uint8)\n",
    "#             plt.imshow(pad_image)\n",
    "#             plt.show()\n",
    "            \n",
    "            # SAVE THE ORIGINAL NAME OF THE IMAGE FIRST.... AND THEN FOR EACH FACE APPEND THE FACE COUNTER            \n",
    "            face_count += 1\n",
    "            \n",
    "            # ADD TO ROW FACE_FILENAME\n",
    "            row['mask_filename'] = \"mask_\" + face_filename + \"_image_final.png\"\n",
    "            \n",
    "            # SAVE AS 24-BIT PNG WITH THE FORMAT OF IMAGEFILENAME_NO STUFF AND SUFFIX\n",
    "            im = Image.fromarray(pad_image)\n",
    "            im.save(PROCESS_PATH + \"\\\\\" +  face_filename + \"_image_final.png\")\n",
    "            \n",
    "            # [DUPLICATE WITH THE BLACK.PNG]            \n",
    "            # Create the black _cc_occ_labels and _sp_labels (16 bit pngs)\n",
    "            cc_occ_png = PROCESS_PATH + \"\\\\\" +  face_filename + \"_cc_occ_labels.png\"\n",
    "            sp_png = PROCESS_PATH + \"\\\\\" +  face_filename + \"_sp_labels.png\"\n",
    "            mask_png = PROCESS_PATH + '\\\\' + face_filename + \"_mask.png\"\n",
    "            \n",
    "            # black.png is reference image being duplicated\n",
    "            shutil.copyfile(\"black.png\", (cc_occ_png))\n",
    "            shutil.copyfile(\"black.png\", (sp_png))    \n",
    "            \n",
    "            pad_image = cv2.cvtColor(pad_image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(os.path.join(PAD_PATH, row['source_file'] + str(face_index) + '.jpg'), pad_image)\n",
    "            \n",
    "            #add tow to dataset\n",
    "            df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe                              \n",
    "    df.to_csv(os.path.join(CSV_PATH, 'dataset' + '.csv'), index=False)  #save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f4d7a-fb0d-4910-8f24-d43dd0120b3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FaceSeg Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcfc1b58-cdbb-4a6f-88cb-7bdf20aeee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('src_release')\n",
    "\n",
    "#libraries for face segmentation\n",
    "from data_loader import get_dataloader\n",
    "from models.encoder_decoder_faceoccnet import FaceOccNet \n",
    "from torch_utils import torch_load_weights,evaluation,viz_notebook,plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b36df10-db2b-4241-89b7-3856bf10af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_path = (\"./ptlabel_best_model.pth\")\n",
    "fs_model = FaceOccNet(input_channels=3, n_classes=3,is_regularized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882b6e0f-c3c6-4cbe-9bfe-4f5783c8d1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaceOccNet(\n",
       "  (model_enc): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ELU(alpha=1.0, inplace=True)\n",
       "    (3): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): ELU(alpha=1.0, inplace=True)\n",
       "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): ELU(alpha=1.0, inplace=True)\n",
       "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (17): ELU(alpha=1.0, inplace=True)\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (model_dilation): Sequential(\n",
       "    (0): ReflectionPad2d((4, 4, 4, 4))\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\n",
       "    (2): ELU(alpha=1.0, inplace=True)\n",
       "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
       "    (6): ELU(alpha=1.0, inplace=True)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (model_dec): Sequential(\n",
       "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): ELU(alpha=1.0, inplace=True)\n",
       "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): PixelShuffle(upscale_factor=2)\n",
       "    (5): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ELU(alpha=1.0, inplace=True)\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): ELU(alpha=1.0, inplace=True)\n",
       "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): PixelShuffle(upscale_factor=2)\n",
       "    (14): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (16): ELU(alpha=1.0, inplace=True)\n",
       "    (17): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (19): ELU(alpha=1.0, inplace=True)\n",
       "  )\n",
       "  (model_class): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "fs_model.to(fs_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a45f9e5-7819-4dd2-8bad-1f380e33f153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start] Model\n",
      "FaceOccNet(\n",
      "  (model_enc): Sequential(\n",
      "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): ELU(alpha=1.0, inplace=True)\n",
      "    (3): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ELU(alpha=1.0, inplace=True)\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (13): ELU(alpha=1.0, inplace=True)\n",
      "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (17): ELU(alpha=1.0, inplace=True)\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model_dilation): Sequential(\n",
      "    (0): ReflectionPad2d((4, 4, 4, 4))\n",
      "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(4, 4))\n",
      "    (2): ELU(alpha=1.0, inplace=True)\n",
      "    (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(3, 3))\n",
      "    (6): ELU(alpha=1.0, inplace=True)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (model_dec): Sequential(\n",
      "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): ELU(alpha=1.0, inplace=True)\n",
      "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): PixelShuffle(upscale_factor=2)\n",
      "    (5): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ELU(alpha=1.0, inplace=True)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ELU(alpha=1.0, inplace=True)\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): PixelShuffle(upscale_factor=2)\n",
      "    (14): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (15): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (16): ELU(alpha=1.0, inplace=True)\n",
      "    (17): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (19): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (model_class): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (drop): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "[End] Model\n",
      "[Start] Keras viz\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ReflectionPad2d-1          [-1, 3, 130, 130]               0\n",
      "            Conv2d-2         [-1, 64, 128, 128]           1,792\n",
      "               ELU-3         [-1, 64, 128, 128]               0\n",
      "   ReflectionPad2d-4         [-1, 64, 130, 130]               0\n",
      "            Conv2d-5          [-1, 128, 64, 64]          73,856\n",
      "               ELU-6          [-1, 128, 64, 64]               0\n",
      "       BatchNorm2d-7          [-1, 128, 64, 64]             256\n",
      "   ReflectionPad2d-8          [-1, 128, 66, 66]               0\n",
      "            Conv2d-9          [-1, 128, 64, 64]         147,584\n",
      "              ELU-10          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-11          [-1, 128, 64, 64]             256\n",
      "  ReflectionPad2d-12          [-1, 128, 66, 66]               0\n",
      "           Conv2d-13          [-1, 128, 64, 64]         147,584\n",
      "              ELU-14          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-15          [-1, 128, 64, 64]             256\n",
      "  ReflectionPad2d-16          [-1, 128, 66, 66]               0\n",
      "           Conv2d-17          [-1, 256, 32, 32]         295,168\n",
      "              ELU-18          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-19          [-1, 256, 32, 32]             512\n",
      "  ReflectionPad2d-20          [-1, 256, 40, 40]               0\n",
      "           Conv2d-21          [-1, 256, 32, 32]         590,080\n",
      "              ELU-22          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-23          [-1, 256, 32, 32]             512\n",
      "  ReflectionPad2d-24          [-1, 256, 38, 38]               0\n",
      "           Conv2d-25          [-1, 256, 32, 32]         590,080\n",
      "              ELU-26          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-27          [-1, 256, 32, 32]             512\n",
      "          Dropout-28          [-1, 512, 32, 32]               0\n",
      "  ReflectionPad2d-29          [-1, 512, 34, 34]               0\n",
      "           Conv2d-30          [-1, 512, 32, 32]       2,359,808\n",
      "              ELU-31          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-32          [-1, 512, 32, 32]           1,024\n",
      "     PixelShuffle-33          [-1, 128, 64, 64]               0\n",
      "  ReflectionPad2d-34          [-1, 128, 66, 66]               0\n",
      "           Conv2d-35          [-1, 128, 64, 64]         147,584\n",
      "              ELU-36          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-37          [-1, 128, 64, 64]             256\n",
      "  ReflectionPad2d-38          [-1, 128, 66, 66]               0\n",
      "           Conv2d-39          [-1, 128, 64, 64]         147,584\n",
      "              ELU-40          [-1, 128, 64, 64]               0\n",
      "      BatchNorm2d-41          [-1, 128, 64, 64]             256\n",
      "     PixelShuffle-42         [-1, 32, 128, 128]               0\n",
      "  ReflectionPad2d-43         [-1, 32, 130, 130]               0\n",
      "           Conv2d-44         [-1, 32, 128, 128]           9,248\n",
      "              ELU-45         [-1, 32, 128, 128]               0\n",
      "  ReflectionPad2d-46         [-1, 32, 130, 130]               0\n",
      "           Conv2d-47         [-1, 32, 128, 128]           9,248\n",
      "              ELU-48         [-1, 32, 128, 128]               0\n",
      "           Conv2d-49          [-1, 3, 128, 128]             867\n",
      "================================================================\n",
      "Total params: 4,524,323\n",
      "Trainable params: 4,524,323\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 183.00\n",
      "Params size (MB): 17.26\n",
      "Estimated Total Size (MB): 200.44\n",
      "----------------------------------------------------------------\n",
      "[End] Keras viz\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "print('[Start] Model')\n",
    "print(fs_model)\n",
    "print('[End] Model')    \n",
    "print('[Start] Keras viz')\n",
    "summary(fs_model,(3,128,128))\n",
    "print('[End] Keras viz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ebf209b-af3f-45b1-a02b-91f3888a0100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./ptlabel_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# You have to set def load in serialization.py to have its map_location parameter = 'cpu'\n",
    "if os.path.exists(load_model_path) and os.path.isfile(load_model_path):\n",
    "    _, _ = torch_load_weights(fs_model, None, load_model_path, model_only=True)\n",
    "    print(f'Loaded model from {load_model_path}')\n",
    "else:\n",
    "    print(f'The model does not exist in {load_model_path} or is not a file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5afa0032-b678-4839-9481-06001c159fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm as fs_tqdm\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "from data_tools import decode_mask2img,encode_img2mask\n",
    "\n",
    "'''\n",
    "Visualization function for tensorboard and notebook\n",
    "'''\n",
    "def tf_viz_img(mask_tmp,i,pred=True):\n",
    "    if pred:\n",
    "        mask_tmp = torch.argmax(mask_tmp[i], dim=0).numpy().copy()\n",
    "    else:\n",
    "        mask_tmp = mask_tmp[i].numpy().copy()\n",
    "    mask_tmp = decode_mask2img(mask_tmp)\n",
    "    mask_tmp = np.transpose(mask_tmp, (2,0,1))\n",
    "    mask_tmp = mask_tmp / 255.0\n",
    "    return mask_tmp\n",
    "\n",
    "'''\n",
    "Main Visualization function\n",
    "'''\n",
    "def viz_notebook_brew(fs_model,eval_dataloader,fs_device,ibv_stop=-1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    unorm = torchvision.transforms.Compose([ torchvision.transforms.Normalize((-1, -1, -1), (2, 2, 2))])\n",
    "    #batch_val = iter(eval_dataloader).next()\n",
    "    fs_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ibv, batch_val in fs_tqdm(enumerate(eval_dataloader),\n",
    "                               desc='viz'):\n",
    "            fs_img, mask_gt, mask_sp, fn = batch_val\n",
    "            pred_mask, _ = fs_model(fs_img.to(fs_device))\n",
    "            pred_mask = pred_mask.cpu()\n",
    "            mask_gt = mask_gt.cpu().data\n",
    "            face_count = 0\n",
    "            for b in range(pred_mask.shape[0]):\n",
    "                pred_tmp = tf_viz_img(pred_mask,b,pred=True)\n",
    "                # mask_gt_tmp = tf_viz_img(mask_gt,b,pred=False)\n",
    "                pred_tmp = np.transpose(pred_tmp, (1,2,0))\n",
    "                # mask_gt_tmp = np.transpose(mask_gt_tmp, (1,2,0))\n",
    "                ##plotting\n",
    "#                 fig = plt.figure()\n",
    "#                 plt.subplot(1,3,1)\n",
    "#                 plt.title(f'Image {fs_img[b].shape[2]}')\n",
    "#                 plt.imshow(np.transpose(unorm(fs_img[b]), (1,2,0)))\n",
    "#                 plt.axis('off')\n",
    "                print(\"IMAGE FILENAME IS: \" + fn[face_count])\n",
    "                                \n",
    "                # TURN THE BLUE AND GREEN PRED_TMP TO WHITE\n",
    "                # Convert non-black pixels to white\n",
    "                non_black_pixels_mask = np.any(pred_tmp != [0, 0, 0], axis=-1)  \n",
    "                pred_tmp[non_black_pixels_mask] = [1, 1, 1]     \n",
    "                \n",
    "#                 plt.subplot(1,3,2)\n",
    "#                 plt.title(f'Prediction {pred_tmp.shape[0]}')\n",
    "#                 plt.imshow(pred_tmp)\n",
    "#                 plt.axis('off')                                                                                \n",
    "                plt.imsave(MASK_PATH + '\\\\' + 'mask_' + fn[face_count], pred_tmp)\n",
    "                \n",
    "                face_count+=1\n",
    "                \n",
    "#                 plt.show()\n",
    "#                 plt.close(fig)\n",
    "            if ibv_stop == ibv:\n",
    "                break        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e05db-c29a-4fe5-b58c-25037ef817a6",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f661e02",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:53:45,546 - part_label_dataset - INFO - reading the image files...\n",
      "2023-03-06 16:53:45,548 - part_label_dataset - INFO - finished initializing the dataloader 1 files.\n",
      "viz: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE FILENAME IS: girl_0_image_final.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_girl_0_image_final.png\n"
     ]
    }
   ],
   "source": [
    "folders = ['img_celeba_56', 'img_celeba_83']\n",
    "\n",
    "# for i in range (150, 153):\n",
    "#     folders.append('img_celeba_' + str(i))\n",
    "\n",
    "output_folder = os.path.join(os.getcwd(), \"faceseg-outs\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "for FOLDER_NAME in folders:\n",
    "    #TODO: update the paths as needed\n",
    "    #FOLDER_NAME = '2--Demonstration'\n",
    "    FOLDER_PATH = os.path.join(os.getcwd(), 'images', FOLDER_NAME)\n",
    "    SET_FOLDER = os.path.join(os.getcwd(), output_folder, FOLDER_NAME)\n",
    "    BBOX_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_box')\n",
    "    PAD_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_pad')\n",
    "    ORIG_PAD_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_original_pad')\n",
    "    PROCESS_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_process')\n",
    "    CSV_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_csv')\n",
    "    \n",
    "    if not os.path.exists(SET_FOLDER):\n",
    "        os.mkdir(SET_FOLDER)\n",
    "    \n",
    "    if not os.path.exists(BBOX_PATH):\n",
    "        os.mkdir(BBOX_PATH)\n",
    "    \n",
    "    if not os.path.exists(BBOX_PATH):\n",
    "        os.mkdir(BBOX_PATH)\n",
    "\n",
    "    if not os.path.exists(PAD_PATH):\n",
    "        os.mkdir(PAD_PATH)\n",
    "\n",
    "    if not os.path.exists(ORIG_PAD_PATH):\n",
    "        os.mkdir(ORIG_PAD_PATH)\n",
    "\n",
    "    if not os.path.exists(PROCESS_PATH):\n",
    "        os.mkdir(PROCESS_PATH)\n",
    "\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        os.mkdir(CSV_PATH)\n",
    "        \n",
    "    MASK_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_mask')\n",
    "\n",
    "    if not os.path.exists(MASK_PATH):\n",
    "        os.mkdir(MASK_PATH)\n",
    "        \n",
    "    # [FACE EXTRACTION PART]\n",
    "    pipeline(model, device)\n",
    "\n",
    "    # [FACE SEGMENTATION PART]\n",
    "    counter = 0\n",
    "\n",
    "    while len(glob.glob(os.path.join(PROCESS_PATH, '*.png'))) > 0:\n",
    "        counter = counter + 1\n",
    "\n",
    "        #create intermediate folder\n",
    "        INTERMEDIATE_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_intermediate_' + str(counter))\n",
    "        if not os.path.exists(INTERMEDIATE_PATH):\n",
    "            os.mkdir(INTERMEDIATE_PATH)\n",
    "\n",
    "        # loop through the images in process path\n",
    "        for index, path in enumerate(glob.glob(os.path.join(PROCESS_PATH, '*.png'))):\n",
    "\n",
    "            if index >= 200 * 3:\n",
    "                break\n",
    "\n",
    "            file = os.path.basename(path) #extract file name\n",
    "            source = os.path.join(PROCESS_PATH, file) # source + file name\n",
    "            destination =  os.path.join(INTERMEDIATE_PATH, file) # destination + file name\n",
    "\n",
    "            os.rename(source, destination) #move images to the destination folder\n",
    "\n",
    "        eval_dataloader = get_dataloader((INTERMEDIATE_PATH,),\n",
    "                              batch_size=250,\n",
    "                              mode='eval', \n",
    "                              num_workers = 4,\n",
    "                              n_classes=3,\n",
    "                              dataset_name='PartLabel')\n",
    "\n",
    "        viz_notebook_brew(fs_model,eval_dataloader,fs_device,ibv_stop=0)\n",
    "\n",
    "    # -----\n",
    "\n",
    "    RESTORED_MASK_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_restored_mask')\n",
    "    APPLIED_MASK_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_applied_mask')\n",
    "    if not os.path.exists(RESTORED_MASK_PATH):\n",
    "        os.mkdir(RESTORED_MASK_PATH)\n",
    "\n",
    "    if not os.path.exists(APPLIED_MASK_PATH):\n",
    "        os.mkdir(APPLIED_MASK_PATH)    \n",
    "\n",
    "    # LOAD DATASET\n",
    "    faces_df = pd.read_csv(CSV_PATH + \"\\\\dataset.csv\")\n",
    "    pixels_df = pd.DataFrame()\n",
    "    no_whites_df = pd.DataFrame()\n",
    "\n",
    "    # PER MASK FILES IN LOCATION\n",
    "    masks = glob.glob(MASK_PATH + \"/*.png\")\n",
    "    for mask in masks:\n",
    "        with open(mask, 'rb') as file:\n",
    "            # GET THE FILENAME       \n",
    "            filename = os.path.basename(MASK_PATH + mask)         \n",
    "            print(filename)\n",
    "\n",
    "            # MATCH FILENAME WITH DATASET\n",
    "            face_row = faces_df.loc[faces_df['mask_filename'] == filename]        \n",
    "\n",
    "            # SET THE RESTORED FILENAME \n",
    "            restored_filename = \"restored_\" + filename                \n",
    "            face_row['filename'] = restored_filename  \n",
    "\n",
    "            # GET THE ORIGINAL SIZE\n",
    "            x_size = face_row['x2_pad'] - face_row['x1_pad']\n",
    "            y_size = face_row['y2_pad'] - face_row['y1_pad']        \n",
    "            greater_size = max(x_size.item(), y_size.item())        \n",
    "            restored_size = (greater_size, greater_size)                \n",
    "\n",
    "            # OPEN AND PROCESS IMAGE\n",
    "            img = Image.open(file).convert(\"RGB\")        \n",
    "            img = img.resize(restored_size)\n",
    "\n",
    "            img_arr = np.array(img)\n",
    "\n",
    "            # Convert non-black pixels to white\n",
    "            non_black_pixels_mask = np.any(img_arr != [0, 0, 0], axis=-1)          \n",
    "            img_arr[non_black_pixels_mask] = [255, 255, 255]\n",
    "\n",
    "            # CHECK NUMBER OF PIXELS AND UNIQUE VALUES WITH THIS\n",
    "            # unique, counts = np.unique(img_arr, return_counts=True)\n",
    "            # print(np.asarray((unique, counts)).T)\n",
    "            # CHECK UNIQUE VALUES WITH THIS\n",
    "            # with np.printoptions(threshold=np.inf):\n",
    "            #     print(img_arr)\n",
    "\n",
    "            # COUNT PIXELS FASTER ALTERNATIVE\n",
    "            unique, counts = np.unique(img_arr, return_counts=True)\n",
    "            if unique.size == 2:\n",
    "                total_pixels = np.asarray((unique, counts)).T[1][1] / 3\n",
    "                face_row['pixels'] = total_pixels\n",
    "            else:\n",
    "                total_pixels = 0\n",
    "                face_row['pixels'] = total_pixels\n",
    "                no_whites_df = no_whites_df.append(face_row, ignore_index=True)            \n",
    "                # Convert everything to white\n",
    "                black_pixels_mask = np.any(img_arr == [0, 0, 0], axis=-1)\n",
    "                img_arr[black_pixels_mask] = [255, 255, 255]            \n",
    "\n",
    "            pixels_df = pixels_df.append(face_row, ignore_index=True)\n",
    "\n",
    "            # SAVE THE FILE\n",
    "            sum_img = Image.fromarray(img_arr)\n",
    "            sum_img = sum_img.save(RESTORED_MASK_PATH + \"\\\\\" + restored_filename)\n",
    "\n",
    "            # MASKING HERE   \n",
    "            # OPEN THE FILE AND MATCH THE FILENAME \n",
    "            img_orig = Image.open(ORIG_PAD_PATH + \"\\\\\" + filename)\n",
    "            img_orig = np.array(img_orig)        \n",
    "            # Select the location of all black pixels\n",
    "            black_pixels_mask = np.any(img_arr == [0, 0, 0], axis=-1)\n",
    "            img_orig[black_pixels_mask] = [0, 0, 0]     \n",
    "\n",
    "            sum_img_orig = Image.fromarray(img_orig)\n",
    "            sum_img_orig = sum_img_orig.save(APPLIED_MASK_PATH + \"\\\\\" + filename)\n",
    "\n",
    "    pixels_df.to_csv(os.path.join(CSV_PATH, 'dataset_pixels' + str(int(time.time())) + '.csv'), index=False)  #save to csv        \n",
    "    no_whites_df.to_csv(os.path.join(CSV_PATH, 'dataset_no_whites' + str(int(time.time())) + '.csv'), index=False)  #save to csv      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160e920-7df2-4ce9-84ee-18e62120f88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb1c08-1acf-4216-8358-6a39602ab408",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0ae4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4f540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
