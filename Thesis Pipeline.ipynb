{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c8fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import gdown\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature as feature\n",
    "import xlwings as xw\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#libraries for yolo\n",
    "from pytorchyolo.models import load_model\n",
    "from pytorchyolo.utils.transforms import Resize, DEFAULT_TRANSFORMS\n",
    "from pytorchyolo.utils.utils import non_max_suppression\n",
    "from pytorchyolo.utils.loss import compute_loss\n",
    "\n",
    "from matplotlib.ticker import (FormatStrFormatter, AutoMinorLocator, FuncFormatter, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd6df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weights():\n",
    "    model_file=[\n",
    "        'yolo_face_sthanhng.weights',\n",
    "        'yolo_face_sthanhng.cfg'\n",
    "    ]\n",
    "    \n",
    "    gdrive_url=[\n",
    "        'https://drive.google.com/uc?id=1utquM5TAnfIa1Aq0X9fCvrllHiTWazdD',\n",
    "        'https://drive.google.com/uc?id=1CPUZlYL5ik4d9y6oCyzi0930KgzawI6V'\n",
    "    ]\n",
    "    \n",
    "    cwd=os.getcwd() \n",
    "    if 'weights' in os.listdir(cwd):\n",
    "        for i in range(len(model_file)):\n",
    "            if model_file[i] in os.listdir(os.path.join(cwd, 'weights')):\n",
    "                print(model_file[i] + ':: status : file already exists')\n",
    "            else:\n",
    "                gdown.download(gdrive_url[i],os.path.join(cwd, 'weights', model_file[i]), quiet=False)\n",
    "    else:\n",
    "        os.makedirs(os.path.join(cwd,'weights'))\n",
    "        for i in range(len(model_file)):\n",
    "            gdown.download(gdrive_url[i], os.path.join(cwd, 'weights', model_file[i]), quiet=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847df66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo_face_sthanhng.weights:: status : file already exists\n",
      "yolo_face_sthanhng.cfg:: status : file already exists\n"
     ]
    }
   ],
   "source": [
    "# download the necessary weights for YOLO-Face\n",
    "download_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4752",
   "metadata": {},
   "source": [
    "## YOLOFace with FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a22160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n"
     ]
    }
   ],
   "source": [
    "# Patterned after FGSM tutorial (https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "device, model = load_model('./weights/yolo_face_sthanhng.cfg', \"./weights/yolo_face_sthanhng.weights\")\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "\n",
    "epsilons = [0, .05]\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020b4f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# FGSM attack code\\ndef fgsm_attack(image, epsilon, data_grad, x1, y1, x2, y2):\\n    # Collect the element-wise sign of the data gradient\\n    image = image\\n    sign_data_grad = data_grad.sign()\\n    # Create the perturbed image by adjusting each pixel of the input image\\n    perturbed_image = image\\n    perturbed_image[:, :, y1:y2, x1:x2] = perturbed_image[:, :, y1:y2, x1:x2] + epsilon * sign_data_grad[:, :, y1:y2, x1:x2] # apply it only to the face region\\n    # Adding clipping to maintain [0,1] range\\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\\n    # Return the perturbed image\\n    return perturbed_image\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad, x1, y1, x2, y2):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    image = image\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image\n",
    "    perturbed_image[:, :, y1:y2, x1:x2] = perturbed_image[:, :, y1:y2, x1:x2] + epsilon * sign_data_grad[:, :, y1:y2, x1:x2] # apply it only to the face region\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff92e19",
   "metadata": {},
   "source": [
    "## Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266919a0-06ad-4f2b-987c-c9fc5825b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "  def __init__(self, numPoints, radius):\n",
    "    self.numPoints = numPoints\n",
    "    self.radius = radius\n",
    "\n",
    "  def describe(self, image, eps = 1e-7):\n",
    "    lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints+3), range=(0, self.numPoints + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp\n",
    "\n",
    "# From https://medium.com/mlearning-ai/how-to-plot-color-channels-histogram-of-an-image-in-python-using-opencv-40022032e127\n",
    "# Extracts image's color channel\n",
    "def extract_color_channel(path, face_index, image):\n",
    "    # BGR Image Color Conversion\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_RGB_' + str(face_index) + '.png', rgb)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_HSV_' + str(face_index) + '.png', hsv)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_HSL_' + str(face_index) + '.png', hls)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_LAB_' + str(face_index) + '.png', lab)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_YCRCB_' + str(face_index) + '.png', ycrcb)\n",
    "\n",
    "#     # RGB Image Histogram\n",
    "#     red_hist = cv2.calcHist([rgb], [0], None, [256], [0, 256])\n",
    "#     green_hist = cv2.calcHist([rgb], [1], None, [256], [0, 256])\n",
    "#     blue_hist = cv2.calcHist([rgb], [2], None, [256], [0, 256])\n",
    "\n",
    "#     # HSV Image Histogram\n",
    "#     hue_hist_HSV = cv2.calcHist([hsv], [0], None, [256], [0, 256])\n",
    "#     saturation_hist_HSV = cv2.calcHist([hsv], [1], None, [256], [0, 256])\n",
    "#     value_hist = cv2.calcHist([hsv], [2], None, [256], [0, 256])\n",
    "\n",
    "#     # HLS Image Histogram\n",
    "#     hue_hist_HLS = cv2.calcHist([hls], [0], None, [256], [0, 256])\n",
    "#     lightness_hist_HLS = cv2.calcHist([hls], [1], None, [256], [0, 256])\n",
    "#     saturation_hist_HLS = cv2.calcHist([hls], [2], None, [256], [0, 256])\n",
    "\n",
    "#     # LAB Image Histogram\n",
    "#     lightness_hist_LAB = cv2.calcHist([lab], [0], None, [256], [0, 256])\n",
    "#     a_hist_LAB = cv2.calcHist([lab], [1], None, [256], [0, 256])\n",
    "#     b_hist_LAB = cv2.calcHist([lab], [2], None, [256], [0, 256])\n",
    "\n",
    "#     # YCrCb Image Histogram\n",
    "#     y_hist = cv2.calcHist([ycrcb], [0], None, [256], [0, 256])\n",
    "#     cr_hist = cv2.calcHist([ycrcb], [1], None, [256], [0, 256])\n",
    "#     cb_hist = cv2.calcHist([ycrcb], [2], None, [256], [0, 256])\n",
    "\n",
    "#     # RGB Image Plot\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.imshow(rgb)\n",
    "#     plt.title('RGB Image')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(red_hist, color='r')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 500])\n",
    "#     plt.title('Red Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(green_hist, color='g')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 500])\n",
    "#     plt.title('Green Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 4)\n",
    "#     plt.plot(blue_hist, color='b')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 500])\n",
    "#     plt.title('Blue Histogram')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     #plt.show()\n",
    "\n",
    "    r, g, b = cv2.split(rgb)\n",
    "    \n",
    "    r *= 255\n",
    "    g *= 255\n",
    "    b *= 255\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_R_RGB_' + str(face_index) + '.png', r)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_G_RGB_' + str(face_index) + '.png', g)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_B_RGB_' + str(face_index) + '.png', b)\n",
    "    \n",
    "    r_hist = cv2.calcHist(r, [0], None, [26], [0, 256])\n",
    "    r_hist = r_hist.ravel()\n",
    "    r_hist = r_hist.astype('float')\n",
    "    r_hist /= r_hist.sum()\n",
    "    \n",
    "    g_hist = cv2.calcHist([g], [0], None, [26], [0, 256])\n",
    "    g_hist = g_hist.ravel()\n",
    "    g_hist = g_hist.astype('float')\n",
    "    g_hist /= g_hist.sum()\n",
    "    \n",
    "    b_hist = cv2.calcHist([b], [0], None, [26], [0, 256])\n",
    "    b_hist = b_hist.ravel()\n",
    "    b_hist = b_hist.astype('float')\n",
    "    b_hist /= b_hist.sum()\n",
    "\n",
    "#     # HSV Image Plot\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     #plt.imshow(hsv)\n",
    "#     plt.title('HSV Image')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(hue_hist_HSV, color='c')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 2500])\n",
    "#     plt.title('Hue Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(saturation_hist_HSV, color='m')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Saturation Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 4)\n",
    "#     plt.plot(value_hist, color='y')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Value Histogram')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    s *= 255\n",
    "    v *= 255\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_H_HSV_' + str(face_index) + '.png', h)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_S_HSV_' + str(face_index) + '.png', s)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_V_HSV_' + str(face_index) + '.png', v)\n",
    "    \n",
    "    h_hist_HSV = cv2.calcHist([h], [0], None, [36], [0, 361])\n",
    "    h_hist_HSV = h_hist_HSV.ravel()\n",
    "    h_hist_HSV = h_hist_HSV.astype('float')\n",
    "    h_hist_HSV /= h_hist_HSV.sum()\n",
    "    \n",
    "    s_hist_HSV = cv2.calcHist([s], [0], None, [26], [0, 256])\n",
    "    s_hist_HSV = s_hist_HSV.ravel()\n",
    "    s_hist_HSV = s_hist_HSV.astype('float')\n",
    "    s_hist_HSV /= s_hist_HSV.sum()\n",
    "    \n",
    "    v_hist_HSV = cv2.calcHist([v], [0], None, [26], [0, 256])\n",
    "    v_hist_HSV = v_hist_HSV.ravel()\n",
    "    v_hist_HSV = v_hist_HSV.astype('float')\n",
    "    v_hist_HSV /= v_hist_HSV.sum()\n",
    "    \n",
    "#     # HLS Image Plot\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.imshow(hls)\n",
    "#     plt.title('HLS Image')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(hue_hist_HLS, color='r')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 2500])\n",
    "#     plt.title('Hue Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(lightness_hist_HLS, color='g')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Lightness Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 4)\n",
    "#     plt.plot(saturation_hist_HLS, color='b')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Saturation Histogram')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "    h, l, s = cv2.split(hls)\n",
    "    \n",
    "    l *= 255\n",
    "    s *= 255\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_H_HSL_' + str(face_index) + '.png', h)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_S_HSL_' + str(face_index) + '.png', s)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_L_HSL_' + str(face_index) + '.png', l)\n",
    "    \n",
    "    h_hist_HSL = cv2.calcHist([h], [0], None, [36], [0, 361])\n",
    "    h_hist_HSL = h_hist_HSL.ravel()\n",
    "    h_hist_HSL = h_hist_HSL.astype('float')\n",
    "    h_hist_HSL /= h_hist_HSL.sum()\n",
    "    \n",
    "    l_hist_HSL = cv2.calcHist([l], [0], None, [26], [0, 256])\n",
    "    l_hist_HSL = l_hist_HSL.ravel()\n",
    "    l_hist_HSL = l_hist_HSL.astype('float')\n",
    "    l_hist_HSL /= l_hist_HSL.sum()\n",
    "    \n",
    "    s_hist_HSL = cv2.calcHist([s], [0], None, [26], [0, 256])\n",
    "    s_hist_HSL = s_hist_HSL.ravel()\n",
    "    s_hist_HSL = s_hist_HSL.astype('float')\n",
    "    s_hist_HSL /= s_hist_HSL.sum()\n",
    "    \n",
    "#     # LAB Image Plot\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.imshow(lab)\n",
    "#     plt.title('LAB Image')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(lightness_hist_LAB, color='c')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Lightness Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(a_hist_LAB, color='m')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 20000])\n",
    "#     plt.title('A Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 4)\n",
    "#     plt.plot(b_hist_LAB, color='y')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 20000])\n",
    "#     plt.title('B Histogram')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_L_LAB_' + str(face_index) + '.png', l)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_A_LAB_' + str(face_index) + '.png', a)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_B_LAB_' + str(face_index) + '.png', b)\n",
    "    \n",
    "    l_hist_LAB = cv2.calcHist([l], [0], None, [26], [0, 256])\n",
    "    l_hist_LAB = l_hist_LAB.ravel()\n",
    "    l_hist_LAB = l_hist_LAB.astype('float')\n",
    "    l_hist_LAB /= l_hist_LAB.sum()\n",
    "    \n",
    "    a_hist_LAB = cv2.calcHist([a], [0], None, [26], [0, 256])\n",
    "    a_hist_LAB = a_hist_LAB.ravel()\n",
    "    a_hist_LAB = a_hist_LAB.astype('float')\n",
    "    a_hist_LAB /= a_hist_LAB.sum()\n",
    "    \n",
    "    b_hist_LAB = cv2.calcHist([b], [0], None, [26], [0, 256])\n",
    "    b_hist_LAB = b_hist_LAB.ravel()\n",
    "    b_hist_LAB = b_hist_LAB.astype('float')\n",
    "    b_hist_LAB /= b_hist_LAB.sum()\n",
    "    \n",
    "#     # YCrCb Image Plot\n",
    "#     plt.subplot(4, 1, 1)\n",
    "#     plt.imshow(ycrcb)\n",
    "#     plt.title('YCrCb Image')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.subplot(4, 1, 2)\n",
    "#     plt.plot(y_hist, color='r')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 1000])\n",
    "#     plt.title('Y Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 3)\n",
    "#     plt.plot(cr_hist, color='g')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 20000])\n",
    "#     plt.title('Cr Histogram')\n",
    "\n",
    "#     plt.subplot(4, 1, 4)\n",
    "#     plt.plot(cb_hist, color='b')\n",
    "#     plt.xlim([0, 256])\n",
    "#     plt.ylim([0, 20000])\n",
    "#     plt.title('Cb Histogram')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    \n",
    "    y *= 255\n",
    "    cr *= 255\n",
    "    cb *= 255\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_Y_YCRCB_' + str(face_index) + '.png', y)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_CR_YCRCB_' + str(face_index) + '.png', cr)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_CB_YCRCB_' + str(face_index) + '.png', cb)\n",
    "    \n",
    "    \n",
    "    y_hist = cv2.calcHist([y], [0], None, [26], [0, 256])\n",
    "    y_hist = y_hist.ravel()\n",
    "    y_hist = y_hist.astype('float')\n",
    "    y_hist /= y_hist.sum()\n",
    "    \n",
    "    cr_hist = cv2.calcHist([cr], [0], None, [26], [0, 256])\n",
    "    cr_hist = cr_hist.ravel()\n",
    "    cr_hist = cr_hist.astype('float')\n",
    "    cr_hist /= cr_hist.sum()\n",
    "    \n",
    "    cb_hist = cv2.calcHist([cb], [0], None, [26], [0, 256])\n",
    "    cb_hist = cb_hist.ravel()\n",
    "    cb_hist = cb_hist.astype('float')\n",
    "    cb_hist /= cb_hist.sum()\n",
    "    \n",
    "    face_index = str(face_index)\n",
    "    # rows = itertools.zip_longest([path], [face_index], r_hist, g_hist, b_hist, h_hist_HSV, s_hist_HSV, v_hist_HSV, h_hist_HSL, s_hist_HSL, l_hist_HSL, l_hist_LAB, a_hist_LAB, b_hist_LAB, y_hist, cr_hist, cb_hist)\n",
    "    \n",
    "    # with open(\"color.csv\", \"a\", newline = \"\") as f:\n",
    "    #     if os.stat(\"color.csv\").st_size == 0:\n",
    "    #         csv.writer(f).writerow([\"Path\", \"Face Index\", \"Red\", \"Green\", \"Blue\", \"Hue_HSV\", \"Saturation_HSV\", \"Value_HSV\", \"Hue_HSL\", \"Saturation_HSL\", \"Lightness_HSL\", \"Lightness_LAB\", \"A_LAB\", \"B_LAB\", \"Y\", \"Cr\", \"Cb\"])\n",
    "    #     csv.writer(f).writerows(rows)\n",
    "    \n",
    "    return r_hist, g_hist, b_hist, h_hist_HSV, s_hist_HSV, v_hist_HSV, h_hist_HSL, s_hist_HSL, l_hist_HSL, l_hist_LAB, a_hist_LAB, b_hist_LAB, y_hist, cr_hist, cb_hist\n",
    "\n",
    "# From https://medium.com/mlearning-ai/color-shape-and-texture-feature-extraction-using-opencv-cb1feb2dbd73\n",
    "# Extracts Local Binary Pattern (Texture) of an image\n",
    "def extract_lbp(path, face_index, image):\n",
    "    # reads the input image as a grayscale image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    desc = LocalBinaryPatterns(24, 8)\n",
    "    lbp_hist, lbp_img = desc.describe(gray)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_LBP_' + str(face_index) + '.png', lbp_img)\n",
    "    \n",
    "    # plt.imshow(lbp_img, cmap = plt.get_cmap('gray'))\n",
    "    # plt.show()\n",
    "    # lbp_hist = cv2.calcHist([lbp_img], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # face_index = str(face_index)\n",
    "    # rows = itertools.zip_longest([path], [face_index], lbp_hist)\n",
    "    \n",
    "    # with open(\"lbp.csv\", \"a\", newline = \"\") as f:\n",
    "    #     if os.stat(\"lbp.csv\").st_size == 0:\n",
    "    #         csv.writer(f).writerow([\"Path\", \"Face Index\", \"LBP\"])\n",
    "    #     csv.writer(f).writerows(rows)\n",
    "    \n",
    "    return lbp_hist\n",
    "    \n",
    "# From https://docs.opencv.org/4.x/d2/d2c/tutorial_sobel_derivatives.html and https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154\n",
    "def extract_gradients(path, face_index, image):\n",
    "    # Uses the Sobel Filter to extract the gradients of an image\n",
    "    # reads the input image, then converts BGR color space to RGB\n",
    "    # img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # compute the 1st order Sobel derivative in X-direction\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "    # compute the 1st order Sobel derivative in Y-direction\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    \n",
    "    # combine sobelx and sobely to form sobel\n",
    "    sobel = sobelx + sobely\n",
    "    \n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_SOBELX_' + str(face_index) + '.png', sobelx)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_SOBELY_' + str(face_index) + '.png', sobely)\n",
    "    cv2.imwrite(os.path.join(FOLDER_PATH, os.path.splitext(os.path.basename(path))[0]) + '_SOBEL_' + str(face_index) + '.png', sobel)\n",
    "\n",
    "    # # display sobelx, sobely, and sobel\n",
    "    # plt.imshow(sobelx, cmap = \"gray\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(sobely, cmap = \"gray\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(sobel, cmap = \"gray\")\n",
    "    # plt.show()\n",
    "    \n",
    "    sobelx_hist = cv2.calcHist([np.float32(sobelx)], [0], None, [26], [0, 256])\n",
    "    sobelx_hist = sobelx_hist.ravel()\n",
    "    sobelx_hist = sobelx_hist.astype('float')\n",
    "    sobelx_hist /= sobelx_hist.sum()\n",
    "    \n",
    "    sobely_hist = cv2.calcHist([np.float32(sobely)], [0], None, [26], [0, 256])\n",
    "    sobely_hist = sobely_hist.ravel()\n",
    "    sobely_hist = sobely_hist.astype('float')\n",
    "    sobely_hist /= sobely_hist.sum()\n",
    "    \n",
    "    sobel_hist = cv2.calcHist([np.float32(sobel)], [0], None, [26], [0, 256])\n",
    "    sobel_hist = sobel_hist.ravel()\n",
    "    sobel_hist = sobel_hist.astype('float')\n",
    "    sobel_hist /= sobel_hist.sum()\n",
    "    \n",
    "    # face_index = str(face_index)\n",
    "    # rows = itertools.zip_longest([path], [face_index], sobelx_hist, sobely_hist, sobel_hist)\n",
    "    \n",
    "    # with open(\"gradient.csv\", \"a\", newline = \"\") as f:\n",
    "    #     if os.stat(\"gradient.csv\").st_size == 0:\n",
    "    #         csv.writer(f).writerow([\"Path\", \"Face Index\", \"Sobel X\", \"Sobel Y\", \"Sobel\"])\n",
    "    #     csv.writer(f).writerows(rows)\n",
    "    \n",
    "    return sobelx_hist, sobely_hist, sobel_hist\n",
    "\n",
    "def extract_image_attributes(row, path, face_index, image):\n",
    "    r_hist, g_hist, b_hist, h_hist_HSV, s_hist_HSV, v_hist_HSV, h_hist_HSL, s_hist_HSL, l_hist_HSL, l_hist_LAB, a_hist_LAB, b_hist_LAB, y_hist, cr_hist, cb_hist = extract_color_channel(path, face_index, image)\n",
    "    lbp_hist = extract_lbp(path, face_index, image)\n",
    "    sobelx_hist, sobely_hist, sobel_hist = extract_gradients(path, face_index, image)\n",
    "    \n",
    "    RGB_size = SV_HSV_size = SL_HSL_size = LAB_size = YCRCB_size = 26\n",
    "    \n",
    "    for i in range(0, RGB_size):\n",
    "        row['R_BIN_' + str(i)] = r_hist[i]\n",
    "        \n",
    "    for i in range(0, RGB_size):\n",
    "        row['G_BIN_' + str(i)] = g_hist[i]\n",
    "        \n",
    "    for i in range(0, RGB_size):\n",
    "        row['B_BIN_' + str(i)] = b_hist[i]\n",
    "        \n",
    "    for i in range(0, h_hist_HSV.size):\n",
    "        row['H_HSV_BIN' + str(i)] = h_hist_HSV[i]\n",
    "        \n",
    "    for i in range(0, SV_HSV_size):\n",
    "        row['S_HSV_BIN' + str(i)] = s_hist_HSV[i]\n",
    "        \n",
    "    for i in range(0, SV_HSV_size):\n",
    "        row['V_HSV_BIN' + str(i)] = v_hist_HSV[i]\n",
    "        \n",
    "    for i in range(0, h_hist_HSL.size):\n",
    "        row['H_HSL_BIN' + str(i)] = h_hist_HSL[i]\n",
    "        \n",
    "    for i in range(0, SL_HSL_size):\n",
    "        row['S_HSL_BIN' + str(i)] = s_hist_HSL[i]\n",
    "        \n",
    "    for i in range(0, SL_HSL_size):\n",
    "        row['L_HSL_BIN' + str(i)] = l_hist_HSL[i]\n",
    "        \n",
    "    for i in range(0, LAB_size):\n",
    "        row['L_LAB_BIN' + str(i)] = l_hist_LAB[i]\n",
    "    \n",
    "    for i in range(0, LAB_size):\n",
    "        row['A_LAB_BIN' + str(i)] = a_hist_LAB[i]\n",
    "        \n",
    "    for i in range(0, LAB_size):\n",
    "        row['B_LAB_BIN' + str(i)] = b_hist_LAB[i]\n",
    "        \n",
    "    for i in range(0, YCRCB_size):\n",
    "        row['Y_BIN' + str(i)] = y_hist[i]\n",
    "        \n",
    "    for i in range(0, YCRCB_size):\n",
    "        row['CR_BIN' + str(i)] = cr_hist[i]\n",
    "        \n",
    "    for i in range(0, YCRCB_size):\n",
    "        row['CB_BIN' + str(i)] = cb_hist[i]\n",
    "        \n",
    "    for i in range(0, lbp_hist.size):\n",
    "        row[\"LBP_BIN\" + str(i)] = lbp_hist[i]\n",
    "        \n",
    "    for i in range(0, sobelx_hist.size):\n",
    "        row[\"SOBELX_BIN\" + str(i)] = sobelx_hist[i]\n",
    "        \n",
    "    for i in range(0, sobely_hist.size):\n",
    "        row[\"SOBELY_BIN\" + str(i)] = sobely_hist[i]\n",
    "        \n",
    "    for i in range(0, sobel_hist.size):\n",
    "        row[\"SOBEL_BIN\" + str(i)] = sobel_hist[i]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c215245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_cpu(image):\n",
    "    return image.detach().cpu()\n",
    "\n",
    "# convert 1x3x416x416 to 416x416x3\n",
    "def reshape_image(image):\n",
    "    return np.transpose(np.squeeze(image), (1 ,2, 0))\n",
    "\n",
    "# convert 1x3x416x416 tensor to 416x416x3 numpy image\n",
    "def tensor_to_image(image):\n",
    "    return np.transpose(image.detach().cpu().squeeze().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b600713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_detection_yunet_2022mar.onnx:: status : file already exists\n"
     ]
    }
   ],
   "source": [
    "import minepsilon as minE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833d8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask(filename, face_num, target_bbox):\n",
    "    faces_df = pd.read_csv(CSV_FILE)\n",
    "    filename = \"restored_mask_\" + os.path.splitext(filename)[0] + \"_\" + str(face_num) + \"_image_final.png\"\n",
    "    mask = cv2.imread(os.path.join(os.getcwd(), RESTORED_MASK_PATH, filename))\n",
    "    #print(os.path.join(os.getcwd(), RESTORED_MASK_PATH, filename))\n",
    "    face_row = faces_df.loc[faces_df['filename'] == filename]\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #print(\"mask size before:\", mask.shape)\n",
    "    \n",
    "    mask = transforms.Compose([DEFAULT_TRANSFORMS])((mask, np.zeros((1, 5))))[0].unsqueeze(0)\n",
    "    padded_dim = (int(face_row[\"x2_pad\"] - face_row[\"x1_pad\"]), int(face_row[\"y2_pad\"] - face_row[\"y1_pad\"]))\n",
    "    target_dim = (int(target_bbox[2] - target_bbox[0]), int(target_bbox[3] - target_bbox[1]))\n",
    "    #print(\"x1, y1, orig shape\")\n",
    "    #print(int(face_row[\"x1_pad\"]), int(face_row[\"y1_pad\"]), int(face_row[\"x2_pad\"]), int(face_row[\"y2_pad\"]))\n",
    "    #print(original_shape)\n",
    "    \n",
    "    #print(\"target shape:\", original_shape)\n",
    "    #print(\"yoloshape:\", int(face_row[\"x2\"] - face_row[\"x1\"]), int(face_row[\"y2\"] - face_row[\"y1\"]))\n",
    "    \n",
    "    current_dim = max(mask.shape)\n",
    "    diff_x, diff_y = abs(padded_dim[0] - current_dim) / 2, abs(padded_dim[1] - current_dim) / 2\n",
    "    print(\"first diff:\", diff_x, diff_y)\n",
    "    \n",
    "    if diff_y != 0:\n",
    "        mask = mask[..., int(np.floor(diff_y)):-int(np.ceil(diff_y)), :]\n",
    "    if diff_x != 0:\n",
    "        mask = mask[..., int(np.floor(diff_x)):-int(np.ceil(diff_x))]\n",
    "        \n",
    "    print(mask.shape == padded_dim, mask.shape, padded_dim, target_dim)\n",
    "    \n",
    "    padding = [\n",
    "        int(abs(face_row[\"x1\"] - face_row[\"x1_pad\"])),\n",
    "        int(abs(face_row[\"y1\"] - face_row[\"y1_pad\"])),\n",
    "        int(abs(face_row[\"x2\"] - face_row[\"x2_pad\"])),\n",
    "        int(abs(face_row[\"y2\"] - face_row[\"y2_pad\"]))\n",
    "    ]\n",
    "    \n",
    "    print(\"padding:\", padding)\n",
    "    \n",
    "    new_dim = padded_dim[0] - padding[0] - padding[2], padded_dim[1] - padding[1] - padding[3]\n",
    "    diff_x, diff_y = (target_dim[0] - new_dim[0]) / 2, (target_dim[1] - new_dim[1]) / 2\n",
    "    print(\"second diff:\", diff_x, diff_y)\n",
    "    \n",
    "    padding[0] -= int(np.floor(diff_x))\n",
    "    padding[1] -= int(np.floor(diff_y))\n",
    "    padding[2] -= int(np.ceil(diff_x))\n",
    "    padding[3] -= int(np.ceil(diff_y))\n",
    "    \n",
    "    #print(\"mask size after:\", mask.shape)\n",
    "    #print(\"unpadded bbox:\", (face_row[\"x1\"], face_row[\"y1\"], face_row[\"x2\"], face_row[\"y2\"]))\n",
    "    print(\"adjusted padding:\", padding)\n",
    "    return mask[..., padding[1]:-padding[3], padding[0]:-padding[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7c3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, device):\n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    df = pd.DataFrame() # dataframe storing the dataset\n",
    "    row = {} #the information/columns for a single row in the dataset is stored here\n",
    "    \n",
    "    # Loop over all examples in test set\n",
    "    for path in glob.glob(os.path.join(FOLDER_PATH, '*.jpg')):\n",
    "        row['path'] = path\n",
    "        print(os.path.basename(path))\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # read and transform the image from the path\n",
    "        data = cv2.imread(path)  # read the image\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "        data = transforms.Compose([DEFAULT_TRANSFORMS,Resize(416)])((data, np.zeros((1, 5))))[0].unsqueeze(0) # transform the image\n",
    "    \n",
    "        data = data.to(device)\n",
    "        \n",
    "        \"\"\"\n",
    "        print('Input')\n",
    "        print(data.shape)\n",
    "        plt.imshow(tensor_to_image(data))\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        #print('Model Output')\n",
    "        #print(output)\n",
    "        #print(output.shape)\n",
    "        \n",
    "        # call non max suppression\n",
    "        nms, nms_output = non_max_suppression(output, 0.5, 0.5) #conf_thres and iou_thres = 0.5\n",
    "        \n",
    "        \"\"\"\n",
    "        print('NMS')\n",
    "        print(nms)\n",
    "        print(nms_output)\n",
    "        \"\"\"\n",
    "        \n",
    "        face_list = []\n",
    "        if type(nms_output[0]) is not int:\n",
    "            face_list = nms_output[0]\n",
    "            \n",
    "        # loop through each of the faces in the image\n",
    "        for face_index, face_row in enumerate(face_list): #nms_output[0] because the model is designed to take in several images at a time from the dataloader but we are only loading the image one at a time\n",
    "            row['face_index'] = face_index\n",
    "            print(\"Face\", face_index)\n",
    "            \n",
    "            model.train()\n",
    "            target = torch.tensor([[0.0, face_row[5], face_row[0] / 416, face_row[1] / 416, face_row[2] / 416, face_row[3] / 416]])\n",
    "\n",
    "            target = target.to(device)\n",
    "            \n",
    "            loss, loss_components = compute_loss(model(data), target, model)\n",
    "            #print(loss)\n",
    "            #print(loss_components)\n",
    "            # Calculate the loss\n",
    "            #TODO: check if this is correct when determining what should be the ground truth\n",
    "            #Reference (https://github.com/xuexingyu24/YOLO-V3-in-Pytorch-A-Tutorial-on-Implementation-of-YOLO-V3-Algorithm/blob/master/Yolo_V3_Train_Step_by_Step.ipynb)\n",
    "            \n",
    "            \n",
    "#             x_loss = F.mse_loss(face_row[0], face_row[0])\n",
    "#             y_loss = F.mse_loss(face_row[1], face_row[1])\n",
    "#             w_loss = F.mse_loss(face_row[2], face_row[2])\n",
    "#             h_loss = F.mse_loss(face_row[3], face_row[3])\n",
    "#             obj_loss = F.binary_cross_entropy(face_row[4], torch.tensor(0.))\n",
    "#             cls_loss = F.binary_cross_entropy(face_row[5:], torch.tensor([0.])) # index 0 - face, index 1 - back. only the classification loss was used\n",
    "            \n",
    "#             loss = x_loss + y_loss + w_loss + h_loss + obj_loss + cls_loss\n",
    "            \n",
    "            # get the coordinate of the face bounding box\n",
    "            #(x1, y1) lower left, (x2, y2) upper right\n",
    "            x, y, w, h = face_row[0], face_row[1], face_row[2], face_row[3]\n",
    "            \n",
    "            # cropped image with bounding box\n",
    "            # getting (x1, y1) upper left, (x2, y2) lower right\n",
    "            x1 = max(int(np.floor((x - w / 2).detach().cpu().numpy())), 0)\n",
    "            y1 = max(int(np.floor((y - h / 2).detach().cpu().numpy())), 0)\n",
    "            x2 = min(int(np.ceil((x + w / 2).detach().cpu().numpy())), 415)\n",
    "            y2 = min(int(np.ceil((y + h / 2).detach().cpu().numpy())), 415)\n",
    "            \n",
    "            row['x1'], row['y1'], row['x2'], row['y2'] = x1, y1, x2, y2\n",
    "            \n",
    "            #print('Cropped')\n",
    "            print(x1, y1, x2, y2)\n",
    "            cropped_image = detach_cpu(data)[:, :, y1:y2, x1:x2] #get the first dimension, the channels, and crop it\n",
    "            cropped_image = tensor_to_image(cropped_image) #reshape the image to (w/h, h/w, channel)\n",
    "            #plt.imshow(cropped_image)\n",
    "            #plt.show()\n",
    "            \n",
    "            #TODO: Jay - extract image attributes here\n",
    "            # extract the image attributes from  the 'cropped_image' variable\n",
    "            # save the attributes as row['<column name in the dataset>'] = <data> (see examples above for reference)\n",
    "            \n",
    "            row = extract_image_attributes(row, path, face_index, cropped_image)\n",
    "            \n",
    "            #print('Resized')\n",
    "            cropped_resized_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(128)])((cropped_image, np.zeros((1, 5))))[0], (1, 2, 0))\n",
    "            #plt.imshow(cropped_resized_image)\n",
    "            #plt.show()\n",
    "            \n",
    "            # Zero all existing gradients\n",
    "            model.zero_grad()\n",
    "            data.grad = None\n",
    "\n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward(retain_graph=True) #TODO: Amos - check if this is correct\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "            #print('Gradient')\n",
    "            #print(data_grad)\n",
    "#             print(data_grad.shape)\n",
    "            #plt.imshow(np.transpose(np.clip(data_grad.squeeze(0).numpy(), 0, 1), (1, 2, 0)))\n",
    "            #plt.show()\n",
    "            \n",
    "            bbox = (x1, y1, x2, y2)\n",
    "            mask = load_mask(os.path.basename(path), face_index, bbox)\n",
    "            inverted_mask = 1 - mask\n",
    "            \n",
    "            #print(\"bbox dim:\", bbox)\n",
    "            #print(mask.shape, data[:, :, y1:y2, x1:x2].shape)\n",
    "            \n",
    "            # TODO - Amos - determine the value of epsilon by calling fgsm_attack and changing the value of epsilon (see code below)\n",
    "            # the value of data(image) and data_grad remains constant diba\n",
    "            \n",
    "            #print(\"Calculating min epsilon for YuNet...\")\n",
    "            yn_min_e_face = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yn_det_fn, mask, bbox)\n",
    "            #print(\"Calculating min epsilon for MediaPipe...\")\n",
    "            mp_min_e_face = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.mp_det_fn, mask, bbox)\n",
    "            #print(\"Calculating min epsilon for YoloFace...\")\n",
    "            yf_min_e_face = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yf_det_fn, mask, bbox)\n",
    "            #print(\"yunet min:\", yn_min_e, \"mediapipe min:\", mp_min_e, \"yoloface min:\", yf_min_e)\n",
    "            \n",
    "            yn_min_e_bg = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yn_det_fn, inverted_mask, bbox)\n",
    "            mp_min_e_bg = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.mp_det_fn, inverted_mask, bbox)\n",
    "            yf_min_e_bg = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yf_det_fn, inverted_mask, bbox)\n",
    "            \n",
    "            # Call FGSM Attack\n",
    "            \n",
    "            #perturbed_data = minE.fgsm_attack(data.clone().detach(), yf_min_e, data_grad.clone().detach(), mask, *bbox)\n",
    "            #perturbed_data = fgsm_attack(data, max(yn_min_e, mp_min_e), data_grad) #data is the input image, epsilon\n",
    "            #print(\"can detect faces on unperturbed img?\", minE.mp_det_fn(data.detach()))\n",
    "            #print(f\"can detect faces on perturbed data with e={max(yn_min_e, mp_min_e) - 0.01}?\", minE.mp_det_fn(fgsm_attack(data, max(yn_min_e, mp_min_e) - 0.01, data_grad).detach()))\n",
    "            #print(f\"can detect faces on perturbed img? with e={max(yn_min_e, mp_min_e) - 0.01}\", minE.mp_det_fn(perturbed_data.detach()))\n",
    "            \n",
    "            df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n",
    "            \n",
    "#             plt.imshow(tensor_to_image(perturbed_data))\n",
    "            plt.show()\n",
    "            \n",
    "    df.to_csv(os.path.join(FOLDER_PATH, 'dataset' + str(int(time.time())) + '.csv'), index=False)  #save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3efbbeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on img_celeba_0_test folder\n",
      "000001.jpg\n",
      "Face 0\n",
      "165 35 289 211\n",
      "first diff: 25.0 0.0\n",
      "False torch.Size([1, 3, 298, 248]) (248, 298) (124, 176)\n",
      "padding: [62, 35, 62, 87]\n",
      "second diff: 0.0 0.0\n",
      "adjusted padding: [62, 35, 62, 87]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002.jpg\n",
      "Face 0\n",
      "136 63 266 264\n",
      "first diff: 53.5 0.0\n",
      "False torch.Size([1, 3, 365, 258]) (258, 365) (130, 201)\n",
      "padding: [65, 63, 64, 101]\n",
      "second diff: 0.5 0.0\n",
      "adjusted padding: [65, 63, 63, 101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000003.jpg\n",
      "Face 0\n",
      "169 142 222 226\n",
      "first diff: 31.5 0.0\n",
      "False torch.Size([1, 3, 168, 105]) (105, 168) (53, 84)\n",
      "padding: [26, 42, 26, 41]\n",
      "second diff: 0.0 -0.5\n",
      "adjusted padding: [26, 43, 26, 41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000004.jpg\n",
      "Face 0\n",
      "158 40 253 142\n",
      "first diff: 2.5 0.0\n",
      "False torch.Size([1, 3, 191, 186]) (186, 191) (95, 102)\n",
      "padding: [46, 41, 46, 50]\n",
      "second diff: 0.5 1.0\n",
      "adjusted padding: [46, 40, 45, 49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005.jpg\n",
      "Face 0\n",
      "178 56 235 123\n",
      "first diff: 9.5 0.0\n",
      "False torch.Size([1, 3, 133, 114]) (114, 133) (57, 67)\n",
      "padding: [28, 33, 28, 33]\n",
      "second diff: -0.5 0.0\n",
      "adjusted padding: [29, 33, 28, 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000006.jpg\n",
      "Face 0\n",
      "173 58 263 189\n",
      "first diff: 41.5 0.0\n",
      "False torch.Size([1, 3, 259, 176]) (176, 259) (90, 131)\n",
      "padding: [43, 56, 44, 68]\n",
      "second diff: 0.5 -2.0\n",
      "adjusted padding: [43, 58, 43, 70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000007.jpg\n",
      "Face 0\n",
      "146 69 273 287\n",
      "first diff: 64.0 0.0\n",
      "False torch.Size([1, 3, 383, 255]) (255, 383) (127, 218)\n",
      "padding: [64, 75, 63, 103]\n",
      "second diff: -0.5 6.5\n",
      "adjusted padding: [65, 69, 63, 96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000008.jpg\n",
      "Face 0\n",
      "174 51 240 155\n",
      "first diff: 26.0 0.0\n",
      "False torch.Size([1, 3, 191, 139]) (139, 191) (66, 104)\n",
      "padding: [34, 48, 35, 47]\n",
      "second diff: -2.0 4.0\n",
      "adjusted padding: [36, 44, 37, 43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000009.jpg\n",
      "Face 0\n",
      "194 55 259 146\n",
      "first diff: 28.5 0.0\n",
      "False torch.Size([1, 3, 185, 128]) (128, 185) (65, 91)\n",
      "padding: [32, 46, 31, 46]\n",
      "second diff: 0.0 -1.0\n",
      "adjusted padding: [32, 47, 31, 47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000010.jpg\n",
      "Face 0\n",
      "147 84 285 246\n",
      "first diff: 31.5 0.0\n",
      "False torch.Size([1, 3, 319, 256]) (256, 319) (138, 162)\n",
      "padding: [64, 79, 64, 80]\n",
      "second diff: 5.0 1.0\n",
      "adjusted padding: [59, 78, 59, 79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayba\\AppData\\Local\\Temp\\ipykernel_9664\\2247643175.py:154: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n"
     ]
    }
   ],
   "source": [
    "folders = [\"img_celeba_0_test\"]\n",
    "output_folder = os.path.join(os.getcwd(), \"faceseg-outs\")\n",
    "\n",
    "for FOLDER_NAME in folders:\n",
    "    FOLDER_PATH = os.path.join(os.getcwd(), 'images', FOLDER_NAME)\n",
    "    SET_FOLDER = os.path.join(FOLDER_NAME)\n",
    "    CSV_PATH = os.path.join(os.getcwd(), 'CSV')\n",
    "    RESTORED_MASK_PATH = os.path.join(os.getcwd(), SET_FOLDER, FOLDER_NAME + '_restored_mask')\n",
    "    CSV_FILE = \"\"\n",
    "    for file in os.listdir(CSV_PATH):\n",
    "        if \"dataset_pixels\" in file and FOLDER_NAME in file and file.endswith(\".csv\"):\n",
    "            CSV_FILE = os.path.join(os.getcwd(), CSV_PATH, file)\n",
    "    \n",
    "    print(\"Working on\", FOLDER_NAME, \"folder\")\n",
    "    pipeline(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e8e404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'E:\\\\Documents\\\\GitHub\\\\THS-ST1\\\\images\\\\Test\\\\girl.jpg'\n",
    "\n",
    "# device, model = load_model('./weights/yolo_face_sthanhng.cfg', \"./weights/yolo_face_sthanhng.weights\")\n",
    "\n",
    "# data = cv2.imread(path)  # read the image\n",
    "# # print(data)\n",
    "# data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "# data = transforms.Compose([DEFAULT_TRANSFORMS,Resize(416)])((data, np.zeros((1, 5))))[0].unsqueeze(0) # transform the image\n",
    "# target = torch.tensor([[0.0, 0.0, 0.5, 0.5, 0.5, 0.5]])\n",
    "# target = target.to(device)\n",
    "# print(target.shape)\n",
    "# output = model(data)\n",
    "# for x in output:\n",
    "#     print(x.shape)\n",
    "\n",
    "# compute_loss(output, target, model)\n",
    "# print(output.shape)\n",
    "\n",
    "# for i, yolo_layer in enumerate(model.yolo_layers):\n",
    "#     print(i)\n",
    "#     print(yolo_layer.anchors)\n",
    "#     print(yolo_layer.stride)\n",
    "#     print(yolo_layer.anchors / yolo_layer.stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896c248",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86820af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python program to compute and visualize the\n",
    "# # histogram of Blue channel of image\n",
    "# %matplotlib inline\n",
    "\n",
    "# # importing libraries\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# # reading the input image\n",
    "# img = cv2.imread('mountain.jpg')\n",
    "\n",
    "# print(str(img.shape))\n",
    "# red_hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
    "# green_hist = cv2.calcHist([img], [1], None, [256], [0, 256])\n",
    "# blue_hist = cv2.calcHist([img], [2], None, [256], [0, 256])\n",
    "# print(red_hist.shape)\n",
    "\n",
    "# # computing the histogram of the blue channel of the image\n",
    "# b, g, r = cv2.split(img)\n",
    "# print(\"b shape: \" + str(b.shape))\n",
    "# print(\"b[0] shape: \" + str(b[0].shape))\n",
    "# print(str(b[0]))\n",
    "# hist = cv2.calcHist([b] , [0], None, [26], [0,256])\n",
    "# print(\"hist shape: \" + str(hist.shape))\n",
    "# hist = hist.ravel()\n",
    "# hist = hist.astype('float')\n",
    "# hist /= hist.sum()\n",
    "\n",
    "# print(hist.shape)\n",
    "# print(hist)\n",
    "\n",
    "# # plot the above computed histogram\n",
    "# plt.plot(hist, color='b')\n",
    "# plt.title('Image Histogram For Blue Channel GFG')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74a6dd74-3edf-497b-b295-e14ca31d631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python program to compute and visualize the\n",
    "# # histogram of Blue channel of image\n",
    "# %matplotlib inline\n",
    "\n",
    "# # importing libraries\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# # reading the input image\n",
    "# img = cv2.imread('mountain.jpg')\n",
    "\n",
    "# # computing the histogram of the blue channel of the image\n",
    "# b, g, r = cv2.split(img)\n",
    "# hist = cv2.calcHist([b] , [0], None, [26], [0,256])\n",
    "# hist = hist.ravel()\n",
    "# hist = hist.astype('float')\n",
    "# # hist /= hist.sum()\n",
    "\n",
    "# print(hist.shape)\n",
    "# print(hist)\n",
    "\n",
    "# # plot the above computed histogram\n",
    "# plt.plot(hist, color='b')\n",
    "# plt.title('Image Histogram For Blue Channel GFG')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
