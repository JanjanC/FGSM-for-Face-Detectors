{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gdown\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature as feature\n",
    "import xlwings as xw\n",
    "import torchvision.transforms as transforms\n",
    "from pytorchyolo.models import load_model\n",
    "from pytorchyolo.utils.transforms import Resize, DEFAULT_TRANSFORMS\n",
    "from pytorchyolo.utils.utils import non_max_suppression\n",
    "from matplotlib.ticker import (FormatStrFormatter, AutoMinorLocator, FuncFormatter, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weights():\n",
    "    model_file=[\n",
    "        'face_detection.weights',\n",
    "        'face_detection.cfg'\n",
    "    ]\n",
    "    \n",
    "    gdrive_url=[\n",
    "        'https://drive.google.com/uc?id=1nYY0GbZqhssZvkH14WGo9vJG7y9pfMtV',\n",
    "        'https://drive.google.com/uc?id=1IyGoLxm2VPmtt8NMhZp8KueilzaRwdfg'\n",
    "    ]\n",
    "    \n",
    "    cwd=os.getcwd() \n",
    "    if 'weights' in os.listdir(cwd):\n",
    "        for i in range(len(model_file)):\n",
    "            if model_file[i] in os.listdir(os.path.join(cwd, 'weights')):\n",
    "                print(model_file[i] + ':: status : file already exists')\n",
    "            else:\n",
    "                gdown.download(gdrive_url[i],os.path.join(cwd, 'weights', model_file[i]), quiet=False)\n",
    "    else:\n",
    "        os.makedirs(os.path.join(cwd,'weights'))\n",
    "        for i in range(len(model_file)):\n",
    "            gdown.download(gdrive_url[i], os.path.join(cwd, 'weights', model_file[i]), quiet=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847df66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download the necessary weights for YOLO-Face\n",
    "download_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4752",
   "metadata": {},
   "source": [
    "## YOLOFace with FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterned after FGSM tutorial (https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "device, model = load_model('./weights/face_detection.cfg', \"./weights/face_detection.weights\")\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "\n",
    "epsilons = [0, .05]\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad, x1, y1, x2, y2):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    image = image.detach().cpu()\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image\n",
    "    perturbed_image[:, :, y1:y2, x1:x2] = perturbed_image[:, :, y1:y2, x1:x2] + epsilon * sign_data_grad[:, :, y1:y2, x1:x2] # apply it only to the face region\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b600713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import minepsilon as minE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = os.path.join(os.getcwd(), 'images')\n",
    "print(FOLDER_PATH)\n",
    "\n",
    "def pipeline( model, device):\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for path in glob.glob(os.path.join(FOLDER_PATH, 'girl.jpg')):\n",
    "        print(path)\n",
    "#         print(torch.min(data), torch.max(data))\n",
    "#         print('Input')\n",
    "#         print(data.shape)\n",
    "#         plt.imshow(np.transpose(data.squeeze(0).numpy(), (1, 2, 0)))\n",
    "#         plt.show()\n",
    "        \n",
    "        # read and transform the image from the path\n",
    "        data = cv2.imread(path)  # read the image\n",
    "        print(data.shape)\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "        data = transforms.Compose([DEFAULT_TRANSFORMS,Resize(416)])((data, np.zeros((1, 5))))[0].unsqueeze(0) # transform the image\n",
    "    \n",
    "        data = data.to(device)\n",
    "        \n",
    "        print('Input')\n",
    "        plt.imshow(np.transpose(data.squeeze().detach().cpu().numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "#         print('Model Output')\n",
    "#         print(output)\n",
    "#         print(output.shape)\n",
    "        \n",
    "        # call non max suppression\n",
    "        nms, nms_output = non_max_suppression(output, 0.5, 0.5) #conf_thres and iou_thres = 0.5\n",
    "        print('NMS')\n",
    "        print(nms)\n",
    "        print(nms_output)\n",
    "        \n",
    "        # loop through each of the faces in the image\n",
    "        for face_index, face_row in enumerate(nms_output[0]): #nms_output[0] because the model is designed to take in several images at a time from the dataloader but we are only loading the image one at a time\n",
    "            print('Face ', face_index)\n",
    "            print(face_row)\n",
    "\n",
    "            # Calculate the loss\n",
    "            #TODO: check if this is correct when determining what should be the ground truth\n",
    "            loss = F.binary_cross_entropy(face_row[5:], torch.tensor([0., 0.]))\n",
    "            \n",
    "            # get the coordinate of the face bounding box\n",
    "            #(x1, y1) lower left, (x2, y2) upper right\n",
    "            x1 = int(np.floor((face_row[0] - face_row[2] / 2).detach().cpu().numpy()))\n",
    "            y1 = int(np.floor((face_row[1] - face_row[3] / 2).detach().cpu().numpy()))\n",
    "            x2 = int(np.ceil((face_row[0] + face_row[2] / 2).detach().cpu().numpy()))\n",
    "            y2 = int(np.ceil((face_row[1] + face_row[3] / 2).detach().cpu().numpy()))\n",
    "            \n",
    "            print('Cropped')\n",
    "            print(x1, y1, x2, y2)\n",
    "            cropped_image = data[:, :, y1:y2, x1:x2] #get the first dimension, the channels, and crop it\n",
    "            cropped_image = np.transpose(cropped_image.squeeze().detach().cpu().numpy(), (1, 2, 0)) #reshape the image to (w/h, h/w, channel)\n",
    "            plt.imshow(cropped_image)\n",
    "            plt.show()\n",
    "            \n",
    "            #TODO: Jay - extract image attributes here\n",
    "            # extract the image attributes from  the 'cropped_image' variable\n",
    "            \n",
    "            # Janjan - save the attributes to a csv file\n",
    "            \n",
    "            print('Resized')\n",
    "            cropped_resized_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(128)])((cropped_image, np.zeros((1, 5))))[0], (1, 2, 0))\n",
    "            plt.imshow(cropped_resized_image)\n",
    "            plt.show()\n",
    "            \n",
    "            #TODO: Aaron - perform face segmentation here\n",
    "            # using the 'cropped_resized_image'\n",
    "            \n",
    "            # Zero all existing gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward(retain_graph=True) #TODO: Amos - check if this is correct\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "            print('Gradient')\n",
    "            print(data_grad.shape)      \n",
    "            plt.imshow(np.transpose(np.clip(data_grad.squeeze(0).numpy(), 0, 1), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            \n",
    "            # TODO - Amos - determine the value of epsilon by calling fgsm_attack and changing the value of epsilon (see code below)\n",
    "            # the value of data(image) and data_grad remains constant diba\n",
    "            yn_min_e = minE.min_model_eps(data, data_grad, minE.yn_det_fn)\n",
    "            mp_min_e = minE.min_model_eps(data, data_grad, minE.mp_det_fn)\n",
    "            print(\"yunet min:\", yn_min_e, \"mediapipe min:\", mp_min_e)\n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(data, 0.2, data_grad, x1, y1, x2, y2)\n",
    "#             perturbed_data = fgsm_attack(data, max(yn_min_e, mp_min_e), data_grad) #data is the input image, epsilon\n",
    "#             print(\"can detect faces on unperturbed img?\", minE.mp_det_fn(data.detach()))\n",
    "#             print(f\"can detect faces on perturbed data with e={max(yn_min_e, mp_min_e) - 0.01}?\", minE.mp_det_fn(fgsm_attack(data, max(yn_min_e, mp_min_e) - 0.01, data_grad).detach()))\n",
    "#             print(f\"can detect faces on perturbed img? with e={max(yn_min_e, mp_min_e) - 0.01}\", minE.mp_det_fn(perturbed_data.detach()))\n",
    "            \n",
    "            \n",
    "            # TODO - Janjan cropped the perturbed data as well and put it on top of the face only\n",
    "            print('Perturbed')\n",
    "            plt.imshow(np.transpose(perturbed_data.squeeze().detach().cpu().numpy(), (1, 2, 0)))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f661e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should not be able to detect this (but it can x_x)\n",
    "def mp_det_fn(image):\n",
    "    with minE.mp_face_detection.FaceDetection(min_detection_confidence=0.5, model_selection=0) as face_detection:\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        return results.detections is not None\n",
    "mp_det_fn(cv2.imread(\"_2cantdetect.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266919a0-06ad-4f2b-987c-c9fc5825b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "  def __init__(self, numPoints, radius):\n",
    "    self.numPoints = numPoints\n",
    "    self.radius = radius\n",
    "\n",
    "  def describe(self, image, eps = 1e-7):\n",
    "    lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints+3), range=(0, self.numPoints + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp\n",
    "\n",
    "# Extracts image's color channel\n",
    "def extract_color_channel(image):\n",
    "    # Read Source Image\n",
    "    src = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # BGR Image Color Conversion\n",
    "    rgb = cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "    hls = cv2.cvtColor(src, cv2.COLOR_BGR2HLS)\n",
    "    lab = cv2.cvtColor(src, cv2.COLOR_BGR2LAB)\n",
    "    ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # RGB Image Histogram\n",
    "    red_hist = cv2.calcHist([rgb], [0], None, [256], [0, 255])\n",
    "    green_hist = cv2.calcHist([rgb], [1], None, [256], [0, 255])\n",
    "    blue_hist = cv2.calcHist([rgb], [2], None, [256], [0, 255])\n",
    "\n",
    "    # HSV Image Histogram\n",
    "    hue_hist_HSV = cv2.calcHist([hsv], [0], None, [256], [0, 255])\n",
    "    saturation_hist_HSV = cv2.calcHist([hsv], [1], None, [256], [0, 255])\n",
    "    value_hist = cv2.calcHist([hsv], [2], None, [256], [0, 255])\n",
    "\n",
    "    # HLS Image Histogram\n",
    "    hue_hist_HLS = cv2.calcHist([hls], [0], None, [256], [0, 255])\n",
    "    lightness_hist_HLS = cv2.calcHist([hls], [1], None, [256], [0, 255])\n",
    "    saturation_hist_HLS = cv2.calcHist([hls], [2], None, [256], [0, 255])\n",
    "\n",
    "    # LAB Image Histogram\n",
    "    lightness_hist_LAB = cv2.calcHist([lab], [0], None, [256], [0, 255])\n",
    "    a_hist_LAB = cv2.calcHist([lab], [1], None, [256], [0, 255])\n",
    "    b_hist_LAB = cv2.calcHist([lab], [2], None, [256], [0, 255])\n",
    "\n",
    "    # YCrCb Image Histogram\n",
    "    y_hist = cv2.calcHist([ycrcb], [0], None, [256], [0, 255])\n",
    "    cr_hist = cv2.calcHist([ycrcb], [1], None, [256], [0, 255])\n",
    "    cb_hist = cv2.calcHist([ycrcb], [2], None, [256], [0, 255])\n",
    "\n",
    "    # RGB Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('RGB Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(red_hist, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Red Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(green_hist, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Green Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(blue_hist, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Blue Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # HSV Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(hsv)\n",
    "    plt.title('HSV Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(hue_hist_HSV, color='c')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 2500])\n",
    "    plt.title('Hue Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(saturation_hist_HSV, color='m')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Saturation Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(value_hist, color='y')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Value Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # HLS Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(hls)\n",
    "    plt.title('HLS Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(hue_hist_HLS, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 2500])\n",
    "    plt.title('Hue Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(lightness_hist_HLS, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Lightness Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(saturation_hist_HLS, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Saturation Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # LAB Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(lab)\n",
    "    plt.title('LAB Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(lightness_hist_LAB, color='c')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Lightness Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(a_hist_LAB, color='m')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('A Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(b_hist_LAB, color='y')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('B Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # YCrCb Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(ycrcb)\n",
    "    plt.title('YCrCb Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(y_hist, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Y Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(cr_hist, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('Cr Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(cb_hist, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('Cb Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exctracts Local Binary Pattern of an image\n",
    "def extract_lbp(image):\n",
    "    orig = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
    "    gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    desc = LocalBinaryPatterns(24, 8)\n",
    "    lbp_hist, lbp_img = desc.describe(gray)\n",
    "\n",
    "    plt.imshow(lbp_img, cmap = plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    \n",
    "def extract_gradients(image):\n",
    "    # read the input image as a grayscale image\n",
    "    img = cv2.imread(image, 0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # compute the 1st order Sobel derivative in X-direction\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "    # compute the 1st order Sobel derivative in Y-direction\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "    # display sobelx and sobely\n",
    "    plt.imshow(sobelx, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(sobely)\n",
    "    plt.show()\n",
    "    \n",
    "# Inserts contents to the workbook\n",
    "def insert_to_workbook(rng, content):\n",
    "  rng.value = content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f4cda",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
