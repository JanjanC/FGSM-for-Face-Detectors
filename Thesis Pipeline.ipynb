{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import gdown\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.feature as feature\n",
    "import xlwings as xw\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#libraries for yolo\n",
    "from pytorchyolo.models import load_model\n",
    "from pytorchyolo.utils.transforms import Resize, DEFAULT_TRANSFORMS\n",
    "from pytorchyolo.utils.utils import non_max_suppression\n",
    "\n",
    "from matplotlib.ticker import (FormatStrFormatter, AutoMinorLocator, FuncFormatter, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weights():\n",
    "    model_file=[\n",
    "        'yolo_face_sthanhng.weights',\n",
    "        'yolo_face_sthanhng.cfg'\n",
    "    ]\n",
    "    \n",
    "    gdrive_url=[\n",
    "        'https://drive.google.com/uc?id=1utquM5TAnfIa1Aq0X9fCvrllHiTWazdD',\n",
    "        'https://drive.google.com/uc?id=1CPUZlYL5ik4d9y6oCyzi0930KgzawI6V'\n",
    "    ]\n",
    "    \n",
    "    cwd=os.getcwd() \n",
    "    if 'weights' in os.listdir(cwd):\n",
    "        for i in range(len(model_file)):\n",
    "            if model_file[i] in os.listdir(os.path.join(cwd, 'weights')):\n",
    "                print(model_file[i] + ':: status : file already exists')\n",
    "            else:\n",
    "                gdown.download(gdrive_url[i],os.path.join(cwd, 'weights', model_file[i]), quiet=False)\n",
    "    else:\n",
    "        os.makedirs(os.path.join(cwd,'weights'))\n",
    "        for i in range(len(model_file)):\n",
    "            gdown.download(gdrive_url[i], os.path.join(cwd, 'weights', model_file[i]), quiet=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847df66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download the necessary weights for YOLO-Face\n",
    "download_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4752",
   "metadata": {},
   "source": [
    "## YOLOFace with FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterned after FGSM tutorial (https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)\n",
    "# Define what device we are using\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "device, model = load_model('./weights/yolo_face_sthanhng.cfg', \"./weights/yolo_face_sthanhng.weights\")\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "\n",
    "epsilons = [0, .05]\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad, x1, y1, x2, y2):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    image = image\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image\n",
    "    perturbed_image[:, :, y1:y2, x1:x2] = perturbed_image[:, :, y1:y2, x1:x2] + epsilon * sign_data_grad[:, :, y1:y2, x1:x2] # apply it only to the face region\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266919a0-06ad-4f2b-987c-c9fc5825b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "  def __init__(self, numPoints, radius):\n",
    "    self.numPoints = numPoints\n",
    "    self.radius = radius\n",
    "\n",
    "  def describe(self, image, eps = 1e-7):\n",
    "    lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints+3), range=(0, self.numPoints + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp\n",
    "\n",
    "# From https://medium.com/mlearning-ai/how-to-plot-color-channels-histogram-of-an-image-in-python-using-opencv-40022032e127\n",
    "# Extracts image's color channel\n",
    "def extract_color_channel(path, face_index, image):\n",
    "    # BGR Image Color Conversion\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # RGB Image Histogram\n",
    "    red_hist = cv2.calcHist([rgb], [0], None, [256], [0, 255])\n",
    "    green_hist = cv2.calcHist([rgb], [1], None, [256], [0, 255])\n",
    "    blue_hist = cv2.calcHist([rgb], [2], None, [256], [0, 255])\n",
    "\n",
    "    # HSV Image Histogram\n",
    "    hue_hist_HSV = cv2.calcHist([hsv], [0], None, [256], [0, 255])\n",
    "    saturation_hist_HSV = cv2.calcHist([hsv], [1], None, [256], [0, 255])\n",
    "    value_hist = cv2.calcHist([hsv], [2], None, [256], [0, 255])\n",
    "\n",
    "    # HLS Image Histogram\n",
    "    hue_hist_HLS = cv2.calcHist([hls], [0], None, [256], [0, 255])\n",
    "    lightness_hist_HLS = cv2.calcHist([hls], [1], None, [256], [0, 255])\n",
    "    saturation_hist_HLS = cv2.calcHist([hls], [2], None, [256], [0, 255])\n",
    "\n",
    "    # LAB Image Histogram\n",
    "    lightness_hist_LAB = cv2.calcHist([lab], [0], None, [256], [0, 255])\n",
    "    a_hist_LAB = cv2.calcHist([lab], [1], None, [256], [0, 255])\n",
    "    b_hist_LAB = cv2.calcHist([lab], [2], None, [256], [0, 255])\n",
    "\n",
    "    # YCrCb Image Histogram\n",
    "    y_hist = cv2.calcHist([ycrcb], [0], None, [256], [0, 255])\n",
    "    cr_hist = cv2.calcHist([ycrcb], [1], None, [256], [0, 255])\n",
    "    cb_hist = cv2.calcHist([ycrcb], [2], None, [256], [0, 255])\n",
    "\n",
    "    # RGB Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('RGB Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(red_hist, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Red Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(green_hist, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Green Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(blue_hist, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 500])\n",
    "    plt.title('Blue Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    r, g, b = cv2.split(rgb)\n",
    "    \n",
    "    r_hist = cv2.calcHist([r], [0], None, [26], [0, 255])\n",
    "    r_hist = r_hist.ravel()\n",
    "    r_hist = r_hist.astype('float')\n",
    "    r_hist /= r_hist.sum()\n",
    "    \n",
    "    g_hist = cv2.calcHist([g], [0], None, [26], [0, 255])\n",
    "    g_hist = g_hist.ravel()\n",
    "    g_hist = g_hist.astype('float')\n",
    "    g_hist /= g_hist.sum()\n",
    "    \n",
    "    b_hist = cv2.calcHist([b], [0], None, [26], [0, 255])\n",
    "    b_hist = b_hist.ravel()\n",
    "    b_hist = b_hist.astype('float')\n",
    "    b_hist /= b_hist.sum()\n",
    "\n",
    "    # HSV Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(hsv)\n",
    "    plt.title('HSV Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(hue_hist_HSV, color='c')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 2500])\n",
    "    plt.title('Hue Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(saturation_hist_HSV, color='m')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Saturation Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(value_hist, color='y')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Value Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    h_hist_HSV = cv2.calcHist([h], [0], None, [18], [0, 180])\n",
    "    h_hist_HSV = h_hist_HSV.ravel()\n",
    "    h_hist_HSV = h_hist_HSV.astype('float')\n",
    "    h_hist_HSV /= h_hist_HSV.sum()\n",
    "    \n",
    "    s_hist_HSV = cv2.calcHist([s], [0], None, [26], [0, 256])\n",
    "    s_hist_HSV = s_hist_HSV.ravel()\n",
    "    s_hist_HSV = s_hist_HSV.astype('float')\n",
    "    s_hist_HSV /= s_hist_HSV.sum()\n",
    "    \n",
    "    v_hist_HSV = cv2.calcHist([v], [0], None, [26], [0, 256])\n",
    "    v_hist_HSV = v_hist_HSV.ravel()\n",
    "    v_hist_HSV = v_hist_HSV.astype('float')\n",
    "    v_hist_HSV /= v_hist_HSV.sum()\n",
    "    \n",
    "    # HLS Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(hls)\n",
    "    plt.title('HLS Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(hue_hist_HLS, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 2500])\n",
    "    plt.title('Hue Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(lightness_hist_HLS, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Lightness Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(saturation_hist_HLS, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Saturation Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    h, l, s = cv2.split(hls)\n",
    "    \n",
    "    h_hist_HSL = cv2.calcHist([h], [0], None, [18], [0, 180])\n",
    "    h_hist_HSL = h_hist_HSL.ravel()\n",
    "    h_hist_HSL = h_hist_HSL.astype('float')\n",
    "    h_hist_HSL /= h_hist_HSL.sum()\n",
    "    \n",
    "    l_hist_HSL = cv2.calcHist([l], [0], None, [26], [0, 256])\n",
    "    l_hist_HSL = l_hist_HSL.ravel()\n",
    "    l_hist_HSL = l_hist_HSL.astype('float')\n",
    "    l_hist_HSL /= l_hist_HSL.sum()\n",
    "    \n",
    "    s_hist_HSL = cv2.calcHist([s], [0], None, [26], [0, 256])\n",
    "    s_hist_HSL = s_hist_HSL.ravel()\n",
    "    s_hist_HSL = s_hist_HSL.astype('float')\n",
    "    s_hist_HSL /= s_hist_HSL.sum()\n",
    "    \n",
    "    # LAB Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(lab)\n",
    "    plt.title('LAB Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(lightness_hist_LAB, color='c')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Lightness Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(a_hist_LAB, color='m')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('A Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(b_hist_LAB, color='y')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('B Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    l_hist_LAB = cv2.calcHist([l], [0], None, [26], [0, 256])\n",
    "    l_hist_LAB = l_hist_LAB.ravel()\n",
    "    l_hist_LAB = l_hist_LAB.astype('float')\n",
    "    l_hist_LAB /= l_hist_LAB.sum()\n",
    "    \n",
    "    a_hist_LAB = cv2.calcHist([a], [0], None, [26], [0, 256])\n",
    "    a_hist_LAB = a_hist_LAB.ravel()\n",
    "    a_hist_LAB = a_hist_LAB.astype('float')\n",
    "    a_hist_LAB /= a_hist_LAB.sum()\n",
    "    \n",
    "    b_hist_LAB = cv2.calcHist([b], [0], None, [26], [0, 256])\n",
    "    b_hist_LAB = b_hist_LAB.ravel()\n",
    "    b_hist_LAB = b_hist_LAB.astype('float')\n",
    "    b_hist_LAB /= b_hist_LAB.sum()\n",
    "    \n",
    "    # YCrCb Image Plot\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.imshow(ycrcb)\n",
    "    plt.title('YCrCb Image')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(y_hist, color='r')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 1000])\n",
    "    plt.title('Y Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(cr_hist, color='g')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('Cr Histogram')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(cb_hist, color='b')\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 20000])\n",
    "    plt.title('Cb Histogram')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    \n",
    "    y_hist = cv2.calcHist([y], [0], None, [26], [0, 256])\n",
    "    y_hist = y_hist.ravel()\n",
    "    y_hist = y_hist.astype('float')\n",
    "    y_hist /= y_hist.sum()\n",
    "    \n",
    "    cr_hist = cv2.calcHist([cr], [0], None, [26], [0, 256])\n",
    "    cr_hist = cr_hist.ravel()\n",
    "    cr_hist = cr_hist.astype('float')\n",
    "    cr_hist /= cr_hist.sum()\n",
    "    \n",
    "    cb_hist = cv2.calcHist([cb], [0], None, [26], [0, 256])\n",
    "    cb_hist = cb_hist.ravel()\n",
    "    cb_hist = cb_hist.astype('float')\n",
    "    cb_hist /= cb_hist.sum()\n",
    "    \n",
    "    face_index = str(face_index)\n",
    "    rows = itertools.zip_longest([path], [face_index], r_hist, g_hist, b_hist, h_hist_HSV, s_hist_HSV, v_hist_HSV, h_hist_HSL, s_hist_HSL, l_hist_HSL, l_hist_LAB, a_hist_LAB, b_hist_LAB, y_hist, cr_hist, cb_hist)\n",
    "    \n",
    "    with open(\"color.csv\", \"a\", newline = \"\") as f:\n",
    "        if os.stat(\"color.csv\").st_size == 0:\n",
    "            csv.writer(f).writerow([\"Path\", \"Face Index\", \"Red\", \"Green\", \"Blue\", \"Hue_HSV\", \"Saturation_HSV\", \"Value_HSV\", \"Hue_HSL\", \"Saturation_HSL\", \"Lightness_HSL\", \"Lightness_LAB\", \"A_LAB\", \"B_LAB\", \"Y\", \"Cr\", \"Cb\"])\n",
    "        csv.writer(f).writerows(rows)\n",
    "\n",
    "# From https://medium.com/mlearning-ai/color-shape-and-texture-feature-extraction-using-opencv-cb1feb2dbd73\n",
    "# Extracts Local Binary Pattern (Texture) of an image\n",
    "def extract_lbp(path, face_index, image):\n",
    "    # reads the input image as a grayscale image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    desc = LocalBinaryPatterns(24, 8)\n",
    "    lbp_hist, lbp_img = desc.describe(gray)\n",
    "\n",
    "    plt.imshow(lbp_img, cmap = plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    \n",
    "    #lbp_hist = cv2.calcHist([lbp_img], [0], None, [256], [0, 256])\n",
    "    lbp_hist = lbp_hist.ravel()\n",
    "    lbp_hist = lbp_hist.astype('float')\n",
    "    lbp_hist /= lbp_hist.sum()\n",
    "    \n",
    "    face_index = str(face_index)\n",
    "    rows = itertools.zip_longest([path], [face_index], lbp_hist)\n",
    "    \n",
    "    with open(\"lbp.csv\", \"a\", newline = \"\") as f:\n",
    "        if os.stat(\"lbp.csv\").st_size == 0:\n",
    "            csv.writer(f).writerow([\"Path\", \"Face Index\", \"LBP\"])\n",
    "        csv.writer(f).writerows(rows)\n",
    "    \n",
    "# From https://docs.opencv.org/4.x/d2/d2c/tutorial_sobel_derivatives.html and https://gist.github.com/rahit/c078cabc0a48f2570028bff397a9e154\n",
    "def extract_gradients(path, face_index, image):\n",
    "    # Uses the Sobel Filter to extract the gradients of an image\n",
    "    # reads the input image, then converts BGR color space to RGB\n",
    "    # img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # compute the 1st order Sobel derivative in X-direction\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "    # compute the 1st order Sobel derivative in Y-direction\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    \n",
    "    # combine sobelx and sobely to form sobel\n",
    "    sobel = sobelx + sobely\n",
    "\n",
    "    # display sobelx, sobely, and sobel\n",
    "    plt.imshow(sobelx, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(sobely, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    plt.imshow(sobel, cmap = \"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    sobelx_hist = cv2.calcHist([np.float32(sobelx)], [0], None, [26], [0, 256])\n",
    "    sobelx_hist = sobelx_hist.ravel()\n",
    "    sobelx_hist = sobelx_hist.astype('float')\n",
    "    sobelx_hist /= sobelx_hist.sum()\n",
    "    \n",
    "    sobely_hist = cv2.calcHist([np.float32(sobely)], [0], None, [26], [0, 256])\n",
    "    sobely_hist = sobely_hist.ravel()\n",
    "    sobely_hist = sobely_hist.astype('float')\n",
    "    sobely_hist /= sobely_hist.sum()\n",
    "    \n",
    "    sobel_hist = cv2.calcHist([np.float32(sobel)], [0], None, [26], [0, 256])\n",
    "    sobel_hist = sobel_hist.ravel()\n",
    "    sobel_hist = sobel_hist.astype('float')\n",
    "    sobel_hist /= sobel_hist.sum()\n",
    "    \n",
    "    face_index = str(face_index)\n",
    "    rows = itertools.zip_longest([path], [face_index], sobelx_hist, sobely_hist, sobel_hist)\n",
    "    \n",
    "    with open(\"gradient.csv\", \"a\", newline = \"\") as f:\n",
    "        if os.stat(\"gradient.csv\").st_size == 0:\n",
    "            csv.writer(f).writerow([\"Path\", \"Face Index\", \"Sobel X\", \"Sobel Y\", \"Sobel\"])\n",
    "        csv.writer(f).writerows(rows)\n",
    "\n",
    "def extract_image_attributes(path, face_index, image):\n",
    "    extract_color_channel(path, face_index, image)\n",
    "    extract_lbp(path, face_index, image)\n",
    "    extract_gradients(path, face_index, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c215245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach_cpu(image):\n",
    "    return image.detach().cpu()\n",
    "\n",
    "# convert 1x3x416x416 to 416x416x3\n",
    "def reshape_image(image):\n",
    "    return np.transpose(np.squeeze(image), (1 ,2, 0))\n",
    "\n",
    "# convert 1x3x416x416 tensor to 416x416x3 numpy image\n",
    "def tensor_to_image(image):\n",
    "    return np.transpose(image.detach().cpu().squeeze().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b600713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import minepsilon as minE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = os.path.join(os.getcwd(), 'images')\n",
    "print(FOLDER_PATH)\n",
    "\n",
    "def pipeline( model, device):\n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    df = pd.DataFrame() # dataframe storing the dataset\n",
    "    row = {} #the information/columns for a single row in the dataset is stored here\n",
    "    \n",
    "    # Loop over all examples in test set\n",
    "    for path in glob.glob(os.path.join(FOLDER_PATH, 'couple.jpg')):\n",
    "        row['path'] = path\n",
    "        print(path)\n",
    "        \n",
    "        # read and transform the image from the path\n",
    "        data = cv2.imread(path)  # read the image\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "        data = transforms.Compose([DEFAULT_TRANSFORMS,Resize(416)])((data, np.zeros((1, 5))))[0].unsqueeze(0) # transform the image\n",
    "    \n",
    "        data = data.to(device)\n",
    "        \n",
    "        print('Input')\n",
    "        print(data.shape)\n",
    "        plt.imshow(tensor_to_image(data))\n",
    "        plt.show()\n",
    "        \n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "        \n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "#         print('Model Output')\n",
    "#         print(output)\n",
    "#         print(output.shape)\n",
    "        \n",
    "        # call non max suppression\n",
    "        nms, nms_output = non_max_suppression(output, 0.5, 0.5) #conf_thres and iou_thres = 0.5\n",
    "        print('NMS')\n",
    "        print(nms)\n",
    "        print(nms_output)\n",
    "        \n",
    "        # loop through each of the faces in the image\n",
    "        for face_index, face_row in enumerate(nms_output[0]): #nms_output[0] because the model is designed to take in several images at a time from the dataloader but we are only loading the image one at a time\n",
    "            row['face_index'] = face_index\n",
    "            print('Face ', face_index)\n",
    "            print(face_row)\n",
    "\n",
    "            # Calculate the loss\n",
    "            #TODO: check if this is correct when determining what should be the ground truth\n",
    "            loss = F.binary_cross_entropy(face_row[5:], torch.tensor([0.])) # index 0 - face, index 1 - back. only the classification loss was used\n",
    "            \n",
    "            # get the coordinate of the face bounding box\n",
    "            #(x1, y1) lower left, (x2, y2) upper right\n",
    "            x1 = int(np.floor((face_row[0] - face_row[2] / 2).detach().cpu().numpy()))\n",
    "            y1 = int(np.floor((face_row[1] - face_row[3] / 2).detach().cpu().numpy()))\n",
    "            x2 = int(np.ceil((face_row[0] + face_row[2] / 2).detach().cpu().numpy()))\n",
    "            y2 = int(np.ceil((face_row[1] + face_row[3] / 2).detach().cpu().numpy()))\n",
    "            \n",
    "            row['x1'], row['y1'], row['x2'], row['y2'] = x1, y1, x2, y2\n",
    "            \n",
    "            print('Cropped')\n",
    "            print(x1, y1, x2, y2)\n",
    "            cropped_image = detach_cpu(data)[:, :, y1:y2, x1:x2] #get the first dimension, the channels, and crop it\n",
    "            cropped_image = tensor_to_image(cropped_image) #reshape the image to (w/h, h/w, channel)\n",
    "            plt.imshow(cropped_image)\n",
    "            plt.show()\n",
    "            \n",
    "            #TODO: Jay - extract image attributes here\n",
    "            # extract the image attributes from  the 'cropped_image' variable\n",
    "            # save the attributes as row['<column name in the dataset>'] = <data> (see examples above for reference)\n",
    "            \n",
    "            #extract_image_attributes(cropped_image)\n",
    "            extract_image_attributes(path, face_index, cropped_image)\n",
    "            \n",
    "            print('Resized')\n",
    "            cropped_resized_image = np.transpose(transforms.Compose([DEFAULT_TRANSFORMS,Resize(128)])((cropped_image, np.zeros((1, 5))))[0], (1, 2, 0))\n",
    "            plt.imshow(cropped_resized_image)\n",
    "            plt.show()\n",
    "            \n",
    "            #TODO: Aaron - perform face segmentation here\n",
    "            # using the 'cropped_resized_image'\n",
    "            \n",
    "            # Zero all existing gradients\n",
    "            model.zero_grad()\n",
    "            data.grad = None\n",
    "\n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward(retain_graph=True) #TODO: Amos - check if this is correct\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "            print('Gradient')\n",
    "            print(data_grad.shape)\n",
    "            plt.imshow(np.transpose(np.clip(data_grad.squeeze(0).numpy(), 0, 1), (1, 2, 0)))\n",
    "            plt.show()\n",
    "            \n",
    "            # TODO - Amos - determine the value of epsilon by calling fgsm_attack and changing the value of epsilon (see code below)\n",
    "            # the value of data(image) and data_grad remains constant diba\n",
    "            print(\"Calculating min epsilon for YuNet...\")\n",
    "            yn_min_e = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yn_det_fn, (x1, y1, x2, y2))\n",
    "            print(\"Calculating min epsilon for MediaPipe...\")\n",
    "            mp_min_e = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.mp_det_fn, (x1, y1, x2, y2))\n",
    "            print(\"Calculating min epsilon for YoloFace...\")\n",
    "            yf_min_e = minE.min_model_eps(data.clone().detach(), data_grad.clone().detach(), minE.yf_det_fn, (x1, y1, x2, y2))\n",
    "            print(\"yunet min:\", yn_min_e, \"mediapipe min:\", mp_min_e, \"yoloface min:\", yf_min_e)\n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(data.clone().detach(), 0.2, data_grad.clone().detach(), x1, y1, x2, y2)\n",
    "#             perturbed_data = fgsm_attack(data, max(yn_min_e, mp_min_e), data_grad) #data is the input image, epsilon\n",
    "#             print(\"can detect faces on unperturbed img?\", minE.mp_det_fn(data.detach()))\n",
    "#             print(f\"can detect faces on perturbed data with e={max(yn_min_e, mp_min_e) - 0.01}?\", minE.mp_det_fn(fgsm_attack(data, max(yn_min_e, mp_min_e) - 0.01, data_grad).detach()))\n",
    "#             print(f\"can detect faces on perturbed img? with e={max(yn_min_e, mp_min_e) - 0.01}\", minE.mp_det_fn(perturbed_data.detach()))\n",
    "            \n",
    "            df = df.append(row, ignore_index=True) #append the attributes of one face to the dataframe\n",
    "            \n",
    "            print('Perturbed')\n",
    "            plt.imshow(tensor_to_image(perturbed_data))\n",
    "            plt.show()\n",
    "            \n",
    "    df.to_csv(os.path.join(FOLDER_PATH, 'dataset' + str(int(time.time())) + '.csv'), index=False)  #save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f661e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it should not be able to detect this (but it can x_x)\n",
    "def mp_det_fn(image):\n",
    "    with minE.mp_face_detection.FaceDetection(min_detection_confidence=0.9, model_selection=0) as face_detection:\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        return results.detections is not None\n",
    "mp_det_fn(cv2.imread(\"_2cantdetect.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4799790-4aae-4b20-836f-41e2674bb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import skimage.feature as feature\n",
    "data = cv2.imread(\"_2cantdetect.jpg\")  # read the image\n",
    "data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB) #change to rgb\n",
    "extract_image_attributes(\"aaa\", 11111, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b767d28-f076-4d2e-8e24-9dbdf7a7d6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
