{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4008513027514ed1a27e4a96648edbf2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5d65905be36e447292f24c90f95dd1e0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section import and load the necessary dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b5999618bd9d4456a391556a0b512633",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# import Python libaries \n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4d24089e1b9f400dbad687893be45dd6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# import local libraries\n",
    "from scripts import fgsm\n",
    "from scripts.utils import open_img_as_tensor\n",
    "from scripts.face_detectors import MediaPipe, YuNet, YoloFace\n",
    "from scripts.facesegmentor import FaceSegementor\n",
    "from scripts import image_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "075a43cacc9b41a68b47d0d1aba9b893",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "image_attributes.save_color_images = False\n",
    "image_attributes.save_lbp_images = False\n",
    "image_attributes.save_gradient_images = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73ae087d72c5419285ea1f29d051c27d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Face Segmentor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "08f9a7b180c84863b085aa317261247f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section loads and instantiates the face segmentor from the `facesegmentor.py` python file found under the scripts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "71c689b4b10f4be18851a946e3a015e3",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# instantiate face segmentor\n",
    "faceseg = FaceSegementor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6068f195f6cf4726a5ed675458c2e8be",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Face Detector Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d844f2e4de9147269e5f88d62f704fd5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section loads and instantiates the face detector from the `face_detectors.py` python file found under the scripts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "19de0299efdf411d8b1fc15b0c829d97",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# instantiate face detectors\n",
    "yf = YoloFace()\n",
    "yn = YuNet\n",
    "mp = MediaPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aed3b1f869f748a4b7d7e51240ab6e8e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "786f49fac7c24d66b31d66cc8ee78dc0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The labels for the different perturbation regions (i.e. bbox and face region) are added to a list. Moreover, the models (i.e. YoloFace, YuNet, and MediaPipe) are to be stored under a dictionary. In addition, a label is also generated for each combination of perturbation region with the face detection models through a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "95d44f82e7f44e1198b988bdbe1c8d8c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "label_regions = [\"bbox\", \"face\"] # perturbation regions\n",
    "\n",
    "# dictionaries of face detectors\n",
    "models = {\n",
    "    \"yf\": YoloFace(),\n",
    "    \"yn\": YuNet(),\n",
    "    \"mp\": MediaPipe()\n",
    "}\n",
    "\n",
    "# a function that retrieves the label name based on the face detection and perturbation region\n",
    "def get_label(label_model, label_region):\n",
    "    return \"e_\" + label_region + \"_\" + label_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "362e41301ce14f509c912cbea3a8a695",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Input Folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "172c98b34d41461aa2de14a3b185075a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section defines the path to the folders containing the images that will be included in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1d2b754a1f2f4273a85f3c1348b7d818",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "folders = [r\"./input\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80a669c1001b46e2a46a096bb2d34081",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Dataset Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e27ab9c87fc248fdb00c11ed50923202",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The pipeline for the creation of the dataset is outlined below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e20b22f95cfb4ffb9bf2911289041be9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 675,
    "execution_start": 1692021659125,
    "scrolled": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame()\n",
    "\n",
    "#loops through the list of folders\n",
    "for folder in tqdm(folders, desc=\"All folders progress\"):\n",
    "\n",
    "    #loops through the images within the folder\n",
    "    for file_path in tqdm(glob.glob(os.path.join(folder, \"*.jpg\")), desc=\"Current folder progress\"):\n",
    "\n",
    "        input_img = open_img_as_tensor(file_path) #open the image as tensor\n",
    "\n",
    "        #retrieve the image features, gradient noise, bounding box information, and mask for the face region\n",
    "        feats, grads, bboxes, masks = image_attributes.get_features(file_path, face_segmentor=faceseg)\n",
    "\n",
    "        # iterate through the different perturbation regions\n",
    "        for label_region in label_regions:\n",
    "\n",
    "            # if the perturbation region is for bounding box, create a mask for the bounding box region\n",
    "            if label_region == \"bbox\":\n",
    "                for i in range(len(masks)):\n",
    "                    bbox_mask = masks[i]\n",
    "                    bbox_mask[..., bboxes[i][1]:bboxes[i][3], bboxes[i][0]:bboxes[i][2]] = 1\n",
    "                    masks[i] = bbox_mask\n",
    "            \n",
    "            # determine the minimum perturbation parameter for different face detectors\n",
    "            for model in models:\n",
    "                e_mins = []\n",
    "                # search for the minimum perturbation parameter for the detected faces\n",
    "                for data_grad, mask, bbox in zip(grads, masks, bboxes):\n",
    "                    e_mins.append(fgsm.binary_search(input_img, data_grad, models[model], mask, bbox))\n",
    "                label_name = get_label(model, label_region) # \n",
    "                feats[label_name] = e_mins #save the label in the dictionary\n",
    "    \n",
    "    # transform the list of dictionaries into a dataframe\n",
    "    df_dataset = pd.concat([df_dataset, feats], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "09a1c921bc3a49078b38e806ac0246c6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Once the generation for the dataset has been finished, save the resulting `DataFrame` as a `.csv` file named `\"min_epsilon_dataset.csv\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8a3f8742fb6d4d31a9a0163852d3ab0c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "df_dataset.to_csv(\"min_epsilon_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8f5e2285986c4d52a3e9b4d85d90e8a5",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
