{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4008513027514ed1a27e4a96648edbf2",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5d65905be36e447292f24c90f95dd1e0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section import and load the necessary dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b5999618bd9d4456a391556a0b512633",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# import Python libaries \n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4d24089e1b9f400dbad687893be45dd6",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# import local libraries\n",
    "from scripts import fgsm\n",
    "from scripts.utils import open_img_as_tensor\n",
    "from scripts.face_detectors import MediaPipe, YuNet, YoloFace\n",
    "from scripts.facesegmentor import FaceSegementor\n",
    "from scripts import image_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "075a43cacc9b41a68b47d0d1aba9b893",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "image_attributes.save_color_images = False\n",
    "image_attributes.save_lbp_images = False\n",
    "image_attributes.save_gradient_images = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "73ae087d72c5419285ea1f29d051c27d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Face Segmentor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "08f9a7b180c84863b085aa317261247f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section loads and instantiates the face segmentor from the `facesegmentor.py` python file found under the scripts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "71c689b4b10f4be18851a946e3a015e3",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# instantiate face segmentor\n",
    "faceseg = FaceSegementor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6068f195f6cf4726a5ed675458c2e8be",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Face Detector Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d844f2e4de9147269e5f88d62f704fd5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section loads and instantiates the face detector from the `face_detectors.py` python file found under the scripts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "19de0299efdf411d8b1fc15b0c829d97",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# instantiate face detectors\n",
    "yf = YoloFace()\n",
    "yn = YuNet\n",
    "mp = MediaPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "aed3b1f869f748a4b7d7e51240ab6e8e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "786f49fac7c24d66b31d66cc8ee78dc0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The labels for the different perturbation regions (i.e. bbox and face region) are added to a list. Moreover, the models (i.e. YoloFace, YuNet, and MediaPipe) are to be stored under a dictionary. In addition, a label is also generated for each combination of perturbation region with the face detection models through a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "95d44f82e7f44e1198b988bdbe1c8d8c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "label_regions = [\"bbox\", \"face\"] # perturbation regions\n",
    "\n",
    "# dictionaries of face detectors\n",
    "models = {\n",
    "    \"yf\": YoloFace(),\n",
    "    \"yn\": YuNet(),\n",
    "    \"mp\": MediaPipe()\n",
    "}\n",
    "\n",
    "# a function that retrieves the label name based on the face detection and perturbation region\n",
    "def get_label(label_model, label_region):\n",
    "    return \"e_\" + label_region + \"_\" + label_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "362e41301ce14f509c912cbea3a8a695",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Input Folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "172c98b34d41461aa2de14a3b185075a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "This section defines the path to the folders containing the images that will be included in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1d2b754a1f2f4273a85f3c1348b7d818",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "folders = [r\"./input\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80a669c1001b46e2a46a096bb2d34081",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Dataset Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e27ab9c87fc248fdb00c11ed50923202",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "The pipeline for the creation of the dataset is outlined below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "e20b22f95cfb4ffb9bf2911289041be9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 675,
    "execution_start": 1692021659125,
    "scrolled": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame()\n",
    "\n",
    "#loops through the list of folders\n",
    "for folder in tqdm(folders, desc=\"All folders progress\"):\n",
    "\n",
    "    #loops through the images within the folder\n",
    "    for file_path in tqdm(glob.glob(os.path.join(folder, \"*.jpg\")), desc=\"Current folder progress\"):\n",
    "\n",
    "        input_img = open_img_as_tensor(file_path) #open the image as tensor\n",
    "\n",
    "        #retrieve the image features, gradient noise, bounding box information, and mask for the face region\n",
    "        feats, grads, bboxes, masks = image_attributes.get_features(file_path, face_segmentor=faceseg)\n",
    "\n",
    "        # iterate through the different perturbation regions\n",
    "        for label_region in label_regions:\n",
    "\n",
    "            # if the perturbation region is for bounding box, create a mask for the bounding box region\n",
    "            if label_region == \"bbox\":\n",
    "                for i in range(len(masks)):\n",
    "                    bbox_mask = masks[i]\n",
    "                    bbox_mask[..., bboxes[i][1]:bboxes[i][3], bboxes[i][0]:bboxes[i][2]] = 1\n",
    "                    masks[i] = bbox_mask\n",
    "            \n",
    "            # determine the minimum perturbation parameter for different face detectors\n",
    "            for model in models:\n",
    "                e_mins = []\n",
    "                # search for the minimum perturbation parameter for the detected faces\n",
    "                for data_grad, mask, bbox in zip(grads, masks, bboxes):\n",
    "                    e_mins.append(fgsm.binary_search(input_img, data_grad, models[model], mask, bbox))\n",
    "                label_name = get_label(model, label_region) # \n",
    "                feats[label_name] = e_mins #save the label in the dictionary\n",
    "    \n",
    "    # transform the list of dictionaries into a dataframe\n",
    "    df_dataset = pd.concat([df_dataset, feats], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "09a1c921bc3a49078b38e806ac0246c6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Once the generation for the dataset has been finished, save the resulting `DataFrame` as a `.csv` file named `\"min_epsilon_dataset.csv\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8a3f8742fb6d4d31a9a0163852d3ab0c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "df_dataset.to_csv(\"min_epsilon_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "457ebe350667482a9eec713c77f718a0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ea4f5838-df37-44b8-866b-b9dc1b4dd46c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8f5e2285986c4d52a3e9b4d85d90e8a5",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
