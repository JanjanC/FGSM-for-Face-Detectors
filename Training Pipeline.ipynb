{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "cv_folds = 5\n",
    "\n",
    "if not os.path.isdir(\"model_dumps\"):\n",
    "    os.makedirs(\"model_dumps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filename here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CSV_FILENAME = \"ths-st3 compiled dataset.csv\" #<-- update csv name\n",
    "df_features = pd.read_csv(CSV_FILENAME)\n",
    "df_features = df_features[df_features[\"used_mask\"] == True]\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "df_features = df_features.drop(columns = ['Unnamed: 0', 'path', 'source_w', 'source_h', 'face_index'])\n",
    "df_features = df_features.loc[df_features[\"e_bbox_yf\"] < 3, :]\n",
    "print(df_features.columns)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change string types to numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "categorical_columns = df_features.select_dtypes(include=[bool, object]).columns\n",
    "encoded_columns = df_features[categorical_columns].apply(encoder.fit_transform)\n",
    "encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_features = df_features.copy()\n",
    "df_encoded_features[categorical_columns] = encoded_columns\n",
    "df_encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_regions = [\"bbox\", \"mask\"]\n",
    "non_color_features = [\"w\", \"h\", \"x\", \"y\", \"obj_score\", \"class_score\"]\n",
    "\n",
    "color_channels = {\n",
    "    \"RGB\": (\"R_BIN_\", \"G_BIN_\", \"B_BIN_\"),\n",
    "    \"HSV\": (\"H_HSV_BIN_\", \"S_HSV_BIN_\", \"V_HSV_BIN_\"),\n",
    "    \"HSL\": (\"H_HSL_BIN_\", \"S_HSL_BIN_\", \"L_HSL_BIN_\"),\n",
    "    \"LAB\": (\"L_LAB_BIN_\", \"A_LAB_BIN_\", \"B_LAB_BIN_\"),\n",
    "    \"YCBCR\": (\"Y_BIN_\", \"CR_BIN_\", \"CB_BIN_\"),\n",
    "}\n",
    "\n",
    "label_regions = [\"lbbox\", \"bbox\", \"face\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(color_space, region, label_model=\"yf\", label_region=None):\n",
    "    if label_region is None:\n",
    "        label_region = region if region != \"mask\" else \"face\"\n",
    "        \n",
    "    features = list(non_color_features)\n",
    "    for color_channel in color_channels[color_space]: \n",
    "        features += [color_channel + region + \"_\" + str(i) for i in range(26)]\n",
    "    features += [\"LBP_BIN_\" + region + \"_\" + str(i) for i in range(26)]\n",
    "    features += [\"SOBELX_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    features += [\"SOBELY_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    features += [\"SOBEL_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    \n",
    "    return features, \"e_\" + label_region + \"_\" + label_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNED_COLOR_SPACE = \"HSV\" #<-- pick a colorspace\n",
    "# LABEL_MODEL = \"yf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, label = get_features_and_label(ASSIGNED_COLOR_SPACE, \"mask\")\n",
    "# X_features_mask =  df_encoded_features.loc[:,  features]\n",
    "# y_features_mask = df_encoded_features.loc[:, label].values  #<-- pick label\n",
    "\n",
    "# features, label = get_features_and_label(ASSIGNED_COLOR_SPACE, \"bbox\")\n",
    "# X_features_bbox =  df_encoded_features.loc[:,  features]\n",
    "# y_features_bbox = df_encoded_features.loc[:, label].values  #<-- pick label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_mask, X_test_mask, y_train_mask, y_test_mask = train_test_split(X_features_mask, y_features_mask, test_size = 0.2, random_state=random_state)\n",
    "\n",
    "# print(\"Split shapes\")\n",
    "# print(\"X_train: \", X_train_mask.shape)\n",
    "# print(\"y_train: \", y_train_mask.shape)\n",
    "# print(\"X_test: \", X_test_mask.shape)\n",
    "# print(\"y_test: \", y_test_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_bbox, X_test_bbox, y_train_bbox, y_test_bbox = train_test_split(X_features_bbox, y_features_bbox, test_size = 0.2, random_state=random_state)\n",
    "\n",
    "# print(\"Split shapes\")\n",
    "# print(\"X_train: \", X_train_bbox.shape)\n",
    "# print(\"y_train: \", y_train_bbox.shape)\n",
    "# print(\"X_test: \", X_test_bbox.shape)\n",
    "# print(\"y_test: \", y_test_bbox.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predictions):\n",
    "    return np.sqrt(np.mean(np.square(predictions - actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(actual, predictions):\n",
    "    return np.mean(np.abs(predictions - actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_error(actual, pred):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for a,b in zip(pred, actual):\n",
    "        if a > b:\n",
    "            total += a - b\n",
    "            count += 1\n",
    "    return total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concealment_ratio(actual, pred):\n",
    "    count = 0\n",
    "    for a, b in zip(pred, actual):\n",
    "        if a >= b:\n",
    "            count+= 1\n",
    "            \n",
    "    return count / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(y_true, y_pred):\n",
    "    squared_error_sum = 0\n",
    "    for a, b in zip(y_true, y_pred):\n",
    "        if b < a: #underpredict\n",
    "            squared_error_sum += ((a - b) ** 2 ) * 5 #penalize\n",
    "        else: #overpredict or just right\n",
    "            squared_error_sum += ((a - b) ** 2 )\n",
    "    \n",
    "    mse = squared_error_sum / len(y_true)\n",
    "    \n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "concealment_scorer = make_scorer(custom_scorer, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run All Base Models with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# models = [(RandomForestRegressor, {\"random_state\": random_state}), (SVR, {}), (MLPRegressor, {\"random_state\": random_state})]\n",
    "# label_models = [\"yn\", \"yf\", \"mp\"]\n",
    "\n",
    "# for cur_label_model in label_models:\n",
    "#     feature_set_results = pd.DataFrame()\n",
    "#     for cur_color in color_channels.keys():\n",
    "#         for cur_region in feat_regions:\n",
    "#             features, label = get_features_and_label(cur_color, cur_region, label_model=cur_label_model, label_region=\"lbbox\")\n",
    "#             X = df_encoded_features.loc[:,  features]\n",
    "#             y = df_encoded_features.loc[:, label].values\n",
    "#             for model, params in models:\n",
    "#                 row = {}\n",
    "#                 model = model(**params)\n",
    "#                 scores = cross_validate(model, X, y, cv=cv_folds, scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "#                 row[\"color_space\"] = cur_color\n",
    "#                 row[\"extract_region\"] = cur_region\n",
    "#                 row[\"perturb_region\"] = label\n",
    "#                 row[\"model\"] = type(model).__name__\n",
    "#                 print(cur_color, cur_region, label, type(model).__name__)\n",
    "#                 test_names = [\"test_r2\", \"test_neg_root_mean_squared_error\", \"test_neg_mean_absolute_error\", \"train_r2\", \"train_neg_root_mean_squared_error\", \"train_neg_mean_absolute_error\"]\n",
    "#                 for test_name in test_names:\n",
    "#                     row[test_name + \"_ave\"] = np.mean(scores[test_name])\n",
    "#                     row[test_name + \"_std\"] = np.std(scores[test_name])\n",
    "#                     print('\\tave', test_name, row[test_name + \"_ave\"])\n",
    "#                     print('\\tstd', test_name, row[test_name + \"_std\"])\n",
    "#                     for it, val in enumerate(scores[test_name]):\n",
    "#                         row[test_name + \"_\" + str(it)] = val\n",
    "#                 feature_set_results = pd.concat([feature_set_results, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "\n",
    "#     feature_set_results.to_csv(os.path.join(os.getcwd(), \"faceseg-outs\", cur_label_model + \"_feature_set_results_\" + LABEL_MODEL + \".csv\"))\n",
    "# raise Exception(\"STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/rfr_base_mask_\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "\n",
    "if (os.path.isfile(filename)):\n",
    "    rfr = joblib.load(filename) \n",
    "else:\n",
    "    rfr = RandomForestRegressor(random_state = random_state)\n",
    "    rfr.fit(X_train_mask, y_train_mask)\n",
    "    joblib.dump(rfr, filename) \n",
    "    \n",
    "rfr_pred = rfr.predict(X_test_mask)\n",
    "print(\"RMSE:\", rmse(rfr_pred, y_test_mask))\n",
    "print(\"MAE:\", mae(rfr_pred, y_test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/rfr_base_bbox_\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "\n",
    "if (os.path.isfile(filename)):\n",
    "    rfr = joblib.load(filename) \n",
    "else:\n",
    "    rfr = RandomForestRegressor(random_state = random_state)\n",
    "    rfr.fit(X_train_bbox, y_train_bbox)\n",
    "    joblib.dump(rfr, filename) \n",
    "    \n",
    "rfr_pred = rfr.predict(X_test_bbox)\n",
    "print(\"RMSE:\", rmse(rfr_pred, y_test_bbox))\n",
    "print(\"MAE:\", mae(rfr_pred, y_test_bbox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/svr_base_mask_\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "if (os.path.isfile(filename)):\n",
    "    svr = joblib.load(filename) \n",
    "else:\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train_mask, y_train_mask)\n",
    "    joblib.dump(svr, filename) \n",
    "    \n",
    "svr_pred = svr.predict(X_test_mask)\n",
    "print(\"RMSE:\", rmse(svr_pred, y_test_mask))\n",
    "print(\"MAE:\", mae(svr_pred, y_test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/svr_base_bbox_\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "\n",
    "if (os.path.isfile(filename)):\n",
    "    svr = joblib.load(filename) \n",
    "else:\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train_bbox, y_train_bbox)\n",
    "    joblib.dump(svr, filename)\n",
    "    \n",
    "svr_pred = svr.predict(X_test_bbox)\n",
    "print(\"RMSE:\", rmse(svr_pred, y_test_bbox))\n",
    "print(\"MAE:\", mae(svr_pred, y_test_bbox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptrons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/mpr_base_mask_\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "\n",
    "if (os.path.isfile(filename)):\n",
    "    mpr = joblib.load(filename) \n",
    "else:\n",
    "    mpr = MLPRegressor(random_state = random_state)\n",
    "    mpr.fit(X_train_mask, y_train_mask)\n",
    "    joblib.dump(mpr, filename) \n",
    "    \n",
    "mpr_pred = mpr.predict(X_test_mask)\n",
    "print(\"RMSE:\", rmse(mpr_pred, y_test_mask))\n",
    "print(\"MAE:\", mae(mpr_pred, y_test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = \"model_dumps/mpr_base_bbox_e\" + ASSIGNED_COLOR_SPACE + \".pkl\"\n",
    "\n",
    "if (os.path.isfile(filename)):\n",
    "    mpr = joblib.load(filename) \n",
    "else:\n",
    "    mpr = MLPRegressor(random_state = random_state)\n",
    "    mpr.fit(X_train_bbox, y_train_bbox)\n",
    "    joblib.dump(mpr, filename) \n",
    "\n",
    "mpr_pred = mpr.predict(X_test_bbox)\n",
    "print(\"RMSE:\", rmse(mpr_pred, y_test_bbox))\n",
    "print(\"MAE:\", mae(mpr_pred, y_test_bbox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raise Exception(\"STOP HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and Hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLOR_SPACE = \"HSV\" #<-- pick a colorspace\n",
    "CHOSEN_REGION = \"bbox\" #lbbox next\n",
    "\n",
    "features, _ = get_features_and_label(CHOSEN_COLOR_SPACE, CHOSEN_REGION)\n",
    "label = \"e_face_yf\" #\"e_bbox_mp\"  #<-- pick label\n",
    "\n",
    "X_features =  df_encoded_features.loc[:,  features]\n",
    "y_features = df_encoded_features.loc[:, label].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_features, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.base import clone as clone_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_space = [\n",
    "    {\n",
    "        \"n_estimators\": list(range(100, 351, 50)),\n",
    "        \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "        \"max_depth\": [None, 1, 10, 30, 80, 150],\n",
    "        \"min_samples_split\": [2, 4, 8, 16, 32],\n",
    "        \"min_samples_leaf\": [1, 5, 10, 20],\n",
    "        \"max_features\": [None, \"sqrt\", \"log2\", 0.25, 0.5, 0.75],\n",
    "        \"max_leaf_nodes\": [None, 50, 100, 300],\n",
    "        \"min_impurity_decrease\": [0.0, 0.5],\n",
    "        \"bootstrap\": [False, True],\n",
    "        \"ccp_alpha\": [0.0, 0.5, 1.0],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfr = RandomForestRegressor()\n",
    "gs_rfr = GridSearchCV(rfr, param_space, n_jobs=-1, cv=cv_folds, scoring=concealmnt_ratio)\n",
    "gs_rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Best parameters found:\\n', gs_svr.best_params_)\n",
    "y_pred = gs_rfr.predict(X_val)\n",
    "print(\"Best accuracy: \", rmse(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     \"n_estimators\": Integer(100, 350),\n",
    "#     \"criterion\": Categorical([\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]),\n",
    "#     \"max_depth\": Integer(1, 300),\n",
    "#     \"min_samples_split\": Integer(2, 32),\n",
    "#     \"min_samples_leaf\": Integer(1, 20),\n",
    "#     \"max_features\": Categorical([None, \"sqrt\", \"log2\", 0.25, 0.5, 0.75]),\n",
    "#     \"max_leaf_nodes\": Integer(50, 300),\n",
    "#     \"min_impurity_decrease\": Real(0.0, 2.0),\n",
    "#     \"bootstrap\": Categorical([False, True]),\n",
    "#     \"ccp_alpha\": Real(0.0, 2.0),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rfr = RandomForestRegressor()\n",
    "# bo_rfr = BayesSearchCV(rfr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "# bo_rfr.fit(X_train, y_train)\n",
    "\n",
    "# joblib.dump(bo_rfr, \"model_dumps/rfr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best parameters found:\\n', bo_rfr.best_params_)\n",
    "\n",
    "# print('Test')\n",
    "# y_pred = bo_rfr.predict(X_test)\n",
    "# print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "# print(\"MAE: \", mae(y_test, y_pred))\n",
    "# print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "# print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "# print('Train')\n",
    "# y_pred = bo_rfr.predict(X_train)\n",
    "# print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "# print(\"MAE: \", mae(y_train, y_pred))\n",
    "# print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "# print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfr = RandomForestRegressor()\n",
    "# pipe = Pipeline([('selector', SelectKBest(f_regression)), ('rfr', rfr)])\n",
    "\n",
    "# search_space = {\n",
    "#     \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "#     \"rfr__n_estimators\": Integer(100, 350),\n",
    "#     \"rfr__criterion\": Categorical([\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]),\n",
    "#     \"rfr__max_depth\": Integer(1, 300),\n",
    "#     \"rfr__min_samples_split\": Integer(2, 32),\n",
    "#     \"rfr__min_samples_leaf\": Integer(1, 20),\n",
    "#     \"rfr__max_features\": Categorical([None, \"sqrt\", \"log2\", 0.25, 0.5, 0.75]),\n",
    "#     \"rfr__max_leaf_nodes\": Integer(50, 300),\n",
    "#     \"rfr__min_impurity_decrease\": Real(0.0, 2.0),\n",
    "#     \"rfr__bootstrap\": Categorical([False, True]),\n",
    "#     \"rfr__ccp_alpha\": Real(0.0, 2.0),\n",
    "# }\n",
    "\n",
    "# bo_rfr = BayesSearchCV(pipe, search_space, n_iter=75, n_jobs=-1, cv=cv_folds, random_state=random_state, scoring=concealment_scorer)\n",
    "# bo_rfr.fit(X_train, y_train)\n",
    "# joblib.dump(bo_rfr, \"model_dumps/rfr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "# selected_feat = bo_rfr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "# best_rfr = clone_model(bo_rfr.best_estimator_)\n",
    "# best_rfr.fit(X_train, y_train)\n",
    "# joblib.dump(best_rfr, \"model_dumps/rfr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best params:\\n', bo_rfr.best_params_)\n",
    "# print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "# print(\"Test\")\n",
    "# y_pred = best_rfr.predict(X_test)\n",
    "# print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "# print(\"MAE: \", mae(y_test, y_pred))\n",
    "# print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "# print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "# print(\"Train\")\n",
    "# y_pred = best_rfr.predict(X_train)\n",
    "# print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "# print(\"MAE: \", mae(y_train, y_pred))\n",
    "# print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "# print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "param_space = [\n",
    "    {\n",
    "        \"kernel\": \"poly\",\n",
    "        \"degree\": [3, 5, 10, 15, 20],\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "        \"coef0\": [0.0, 2.5, 5.0],\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0],\n",
    "        \"epsilon\": [0.05, 0.1, .5],\n",
    "        \"shrinking\": [False, True],\n",
    "        \"max_iter\": [-1, 100, 500, 1000],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0],\n",
    "        \"epsilon\": [0.05, 0.1, .5],\n",
    "        \"shrinking\": [False, True],\n",
    "        \"max_iter\": [-1, 100, 500, 1000],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": \"sigmoid\",\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "        \"coef0\": [0.0, 2.5, 5.0],\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0],\n",
    "        \"epsilon\": [0.05, 0.1, .5],\n",
    "        \"shrinking\": [False, True],\n",
    "        \"max_iter\": [-1, 100, 500, 1000],\n",
    "    },\n",
    "    {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"C\": [0.0001, 0.01, 1.0, 100.0, 1000.0],\n",
    "        \"epsilon\": [0.05, 0.1, .5],\n",
    "        \"shrinking\": [False, True],\n",
    "        \"max_iter\": [-1, 100, 500, 1000],\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "svr = SVR()\n",
    "gs_svr = GridSearchCV(svr, param_space, n_jobs=-1, cv=cv_folds)\n",
    "gs_svr.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('Best parameters found:\\n', gs_svr.best_params_)\n",
    "y_pred = gs_svr.predict(X_val)\n",
    "print(\"Best accuracy: \", rmse(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"kernel\": Categorical([\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "    \"degree\": Integer(3, 20),\n",
    "    \"gamma\": Categorical([\"auto\", \"scale\"]),\n",
    "    \"coef0\": Real(0.0, 5.0),\n",
    "    \"tol\": Real(0.0001, 0.1),\n",
    "    \"C\": Real(0.0001, 1000.0),\n",
    "    \"epsilon\": Real(0.05, .5),\n",
    "    \"shrinking\": Categorical([False, True]),\n",
    "    \"max_iter\": Integer(100, 5000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "bo_svr = BayesSearchCV(svr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_svr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_svr, \"model_dumps/svr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', bo_svr.best_params_)\n",
    "\n",
    "print('Test')\n",
    "y_pred = bo_svr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print('Train')\n",
    "y_pred = bo_svr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('svr', svr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"svr__kernel\": Categorical([\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "    \"svr__degree\": Integer(3, 20),\n",
    "    \"svr__gamma\": Categorical([\"auto\", \"scale\"]),\n",
    "    \"svr__coef0\": Real(0.0, 5.0),\n",
    "    \"svr__tol\": Real(0.0001, 0.1),\n",
    "    \"svr__C\": Real(0.0001, 1000.0),\n",
    "    \"svr__epsilon\": Real(0.05, .5),\n",
    "    \"svr__shrinking\": Categorical([False, True]),\n",
    "    \"svr__max_iter\": Integer(100, 5000),\n",
    "}\n",
    "\n",
    "bo_svr = BayesSearchCV(pipe, search_space, n_iter=75, n_jobs=-1, cv=cv_folds, random_state=random_state, scoring=concealment_scorer)\n",
    "bo_svr.fit(X_train, y_train)\n",
    "joblib.dump(bo_svr, \"model_dumps/svr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_svr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_svr = clone_model(bo_svr.best_estimator_)\n",
    "best_svr.fit(X_train, y_train)\n",
    "joblib.dump(best_svr, \"model_dumps/svr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_svr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_svr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_svr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_space = [\n",
    "    {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "        \"max_iter\": [200, 500, 1000],\n",
    "        \"random_state\": random_state,\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"max_fun\": [10000, 15000],\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"adam\",\n",
    "        \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "        \"max_iter\": [200, 500, 1000],\n",
    "        \"random_state\": random_state,\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"batch_size\": ['auto', n_samples // 5, n_samples // 10],\n",
    "        \"learning_rate_init\": [0.0005, 0.001, 0.005],\n",
    "        \"shuffle\": [False, True],\n",
    "        \"early_stopping\": [False, True],\n",
    "        \"validation_fraction\": [0.1, 0.15],\n",
    "        \"n_iter_no_change\": [10, 15],\n",
    "        # not sure abt these values, should we be changing these?\n",
    "        \"beta_1\": [0.75, 0.9],\n",
    "        \"beta_2\": [0.85, 0.999],\n",
    "        \"epsilon\": [1e-07, 1e-08],\n",
    "    },\n",
    "    {\n",
    "        \"solver\": \"sgd\",\n",
    "        \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "        \"max_iter\": [200, 500, 1000],\n",
    "        \"random_state\": random_state,\n",
    "        \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"batch_size\": ['auto', n_samples // 5, n_samples // 10],\n",
    "        \"learning_rate_init\": [0.0005, 0.001, 0.005],\n",
    "        \"shuffle\": [False, True],\n",
    "        \"early_stopping\": [False, True],\n",
    "        \"validation_fraction\": [0.1, 0.15],\n",
    "        \"n_iter_no_change\": [10, 15],\n",
    "        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "        \"momentum\": [0.75, 0.9],\n",
    "        \"nesterovs_momentum\": [False, True],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mpr = MLPRegressor()\n",
    "gs_mpr = GridSearchCV(mpr, param_space, n_jobs=-1, cv=cv_folds)\n",
    "gs_mpr.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "print('Best parameters found:\\n', gs_mpr.best_params_)\n",
    "y_pred = gs_mpr.predict(X_val)\n",
    "print(\"Best accuracy: \", rmse(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sz = X_train.shape[1] * 2 // 3 + 1\n",
    "search_space = {\n",
    "    \"activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"alpha\": Real(0.00001, 0.001),\n",
    "    \"learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"max_iter\": Integer(200, 1000),\n",
    "    \"shuffle\": Categorical([False, True]),\n",
    "    \"tol\": Real(0.0001, 0.1),\n",
    "    \"momentum\": Real(0.75, 0.9),\n",
    "    \"nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"early_stopping\": Categorical([False, True]),\n",
    "    \"validation_fraction\": Real(0.1, 0.15),\n",
    "    \"beta_1\": Real(0.75, 0.9),\n",
    "    \"beta_2\": Real(0.85, 0.999),\n",
    "    \"epsilon\": Real(1e-08, 1e-07),\n",
    "    \"n_iter_no_change\": Integer(10, 15),\n",
    "    \"max_fun\": Integer(10000, 15000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "def custom_loss(y_true, y_pred):\n",
    "    squared_error_sum = 0\n",
    "    for a, b in zip(y_true, y_pred):\n",
    "        if b < a: #underpredict\n",
    "            squared_error_sum += ((a - b) ** 2 ) * 2 #penalize\n",
    "        else: #overpredict or just right\n",
    "            squared_error_sum += ((a - b) ** 2 )\n",
    "    \n",
    "    mse = squared_error_sum / len(y_true)\n",
    "    \n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\"\"\"\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2 * (np.sign(y_true - y_pred) + 1) ** 2)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network._base import DERIVATIVES\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "class CustomMLP(MLPRegressor):\n",
    "    def _backprop(self, X, y, activations, deltas, coef_grads, intercept_grads):\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Forward propagate\n",
    "        activations = self._forward_pass(activations)\n",
    "\n",
    "        # Get loss\n",
    "        loss_func_name = \"custom_loss\"\n",
    "        loss = custom_loss(y, activations[-1])\n",
    "        \"\"\"\n",
    "        loss_func_name = self.loss\n",
    "        if loss_func_name == \"log_loss\" and self.out_activation_ == \"logistic\":\n",
    "            loss_func_name = \"binary_log_loss\"\n",
    "        loss = LOSS_FUNCTIONS[loss_func_name](y, activations[-1])\n",
    "        \"\"\"\n",
    "        # Add L2 regularization term to loss\n",
    "        values = 0\n",
    "        for s in self.coefs_:\n",
    "            s = s.ravel()\n",
    "            values += np.dot(s, s)\n",
    "        loss += (0.5 * self.alpha) * values / n_samples\n",
    "\n",
    "        # Backward propagate\n",
    "        last = self.n_layers_ - 2\n",
    "\n",
    "        # The calculation of delta[last] here works with following\n",
    "        # combinations of output activation and loss function:\n",
    "        # sigmoid and binary cross entropy, softmax and categorical cross\n",
    "        # entropy, and identity with squared loss\n",
    "        deltas[last] = activations[-1] - y\n",
    "\n",
    "        # Compute gradient for the last layer\n",
    "        self._compute_loss_grad(\n",
    "            last, n_samples, activations, deltas, coef_grads, intercept_grads\n",
    "        )\n",
    "\n",
    "        inplace_derivative = DERIVATIVES[self.activation]\n",
    "        # Iterate over the hidden layers\n",
    "        for i in range(self.n_layers_ - 2, 0, -1):\n",
    "            deltas[i - 1] = safe_sparse_dot(deltas[i], self.coefs_[i].T)\n",
    "            inplace_derivative(activations[i], deltas[i - 1])\n",
    "\n",
    "            self._compute_loss_grad(\n",
    "                i - 1, n_samples, activations, deltas, coef_grads, intercept_grads\n",
    "            )\n",
    "\n",
    "        return loss, coef_grads, intercept_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpr = CustomMLP(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "bo_mpr = BayesSearchCV(mpr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_mpr, \"model_dumps/mpr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best parameters found:\\n', bo_mpr.best_params_)\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = bo_mpr.predict(X_test)\n",
    "print(\"RMSE\", rmse(y_test, y_pred))\n",
    "print(\"MAE\", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = bo_mpr.predict(X_train)\n",
    "print(\"RMSE\", rmse(y_train, y_pred))\n",
    "print(\"MAE\", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpr = CustomMLP(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('mpr', mpr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"mpr__activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"mpr__solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"mpr__alpha\": Real(0.00001, 0.001),\n",
    "    \"mpr__learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"mpr__learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"mpr__max_iter\": Integer(200, 1000),\n",
    "    \"mpr__shuffle\": Categorical([False, True]),\n",
    "    \"mpr__tol\": Real(0.0001, 0.1),\n",
    "    \"mpr__momentum\": Real(0.75, 0.9),\n",
    "    \"mpr__nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"mpr__early_stopping\": Categorical([False, True]),\n",
    "    \"mpr__validation_fraction\": Real(0.1, 0.15),\n",
    "    \"mpr__beta_1\": Real(0.75, 0.9),\n",
    "    \"mpr__beta_2\": Real(0.85, 0.999),\n",
    "    \"mpr__epsilon\": Real(1e-08, 1e-07),\n",
    "    \"mpr__n_iter_no_change\": Integer(10, 15),\n",
    "    \"mpr__max_fun\": Integer(10000, 15000),\n",
    "}\n",
    "\n",
    "bo_mpr = BayesSearchCV(pipe, search_space, n_iter=76, n_jobs=-1, cv=cv_folds, random_state=random_state, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "joblib.dump(bo_mpr, \"model_dumps/mpr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_mpr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_mpr = clone_model(bo_mpr.best_estimator_)\n",
    "best_mpr.fit(X_train, y_train)\n",
    "joblib.dump(best_mpr, \"model_dumps/mpr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_mpr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_mpr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_mpr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer Sizes Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp_params = dict([('activation', 'relu'), ('alpha', 0.0006077414104241369), ('beta_1', 0.75), ('beta_2', 0.9174938922030286), ('early_stopping', True), ('epsilon', 1e-08), ('learning_rate', 'invscaling'), ('learning_rate_init', 0.0005), ('max_fun', 10000), ('max_iter', 1000), ('momentum', 0.75), ('n_iter_no_change', 15), ('nesterovs_momentum', True), ('shuffle', False), ('solver', 'adam'), ('tol', 0.0001), ('validation_fraction', 0.15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"new_mlp = MLPRegressor(random_state=random_state, **mlp_params)\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(1, X_train.shape[1] - 1),\n",
    "    \"layers__sz0\": Integer(1, X_train.shape[1] * 2 // 3),\n",
    "    \"layers__sz1\": Integer(1, X_train.shape[1] * 4 // 9),\n",
    "    \"layers__sz2\": Integer(1, X_train.shape[1] * 8 // 27),\n",
    "    \"layers__sz3\": Integer(1, X_train.shape[1] * 16 // 81),\n",
    "    \"layers__d\": Integer(1, 4),\n",
    "}\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Layers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d=4, *args, **kwargs):\n",
    "        for i in range(d):\n",
    "            if i < len(args):\n",
    "                setattr(self, \"sz\" + str(i), args[i])\n",
    "            else:\n",
    "                setattr(self, \"sz\" + str(i), 1)\n",
    "                \n",
    "        self.set_params(**kwargs)\n",
    "        self.d = d\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        sizes = {\"sz\" + str(i): getattr(self, \"sz\" + str(i)) for i in range(self.d)}\n",
    "        sizes[\"d\"] = self.d\n",
    "        return sizes\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        global new_mlp\n",
    "        new_mlp.set_params(hidden_layer_sizes=tuple(getattr(self, \"sz\" + str(i)) for i in range(self.d)))\n",
    "        return X\n",
    "    \n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('layers', Layers()), ('mpr', new_mlp)])\n",
    "search = BayesSearchCV(pipe, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_mlp = MLPRegressor(random_state=random_state, **mlp_params)\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 3, X_train.shape[1] - 1),\n",
    "    \"layers__sz\": Integer(1, X_train.shape[1] - 1),\n",
    "    \"layers__d\": Integer(1, 3),\n",
    "}\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Layers(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, d=3, sz=100):\n",
    "        self.d = d\n",
    "        self.sz = sz\n",
    "        \n",
    "    def get_params(self, deep=False):\n",
    "        return {\"sz\": self.sz, \"d\": self.d}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        global new_mlp\n",
    "        new_mlp.set_params(hidden_layer_sizes=tuple(self.sz for i in range(self.d)))\n",
    "        return X\n",
    "    \n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('layers', Layers()), ('mpr', new_mlp)])\n",
    "search = BayesSearchCV(pipe, search_space, n_iter=15, n_jobs=-1, cv=cv_folds, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search.fit(X_train, y_train)\n",
    "selected_feat = search.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_mpr = clone_model(search.best_estimator_)\n",
    "best_mpr.fit(X_train.loc[:, selected_feat], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Best params:\\n', search.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_mpr.predict(X_test.loc[:, selected_feat])\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_mpr.predict(X_train.loc[:, selected_feat])\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_loss(y_true, y_pred):\n",
    "    \n",
    "# #     y_true = np.array(y_true)\n",
    "# #     y_pred = np.array(y_pred)\n",
    "    \n",
    "#     squared_error_sum = 0\n",
    "    \n",
    "#     for a, b in zip(y_true, y_pred):\n",
    "#         if b < a: #underpredict\n",
    "#             squared_error_sum += ((a - b) ** 2 ) * 2 #penalize\n",
    "#         else: #overpredict or just right\n",
    "#             squared_error_sum += ((a - b) ** 2 )\n",
    "    \n",
    "#     mse = squared_error_sum / len(y_true)\n",
    "    \n",
    "#     rmse = np.sqrt(mse)\n",
    "    \n",
    "#     return rmse\n",
    "\n",
    "# def baseline_model():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(13, input_shape=(13,), kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# estimator = KerasRegressor(model=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpay as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.init as init\n",
    "# import torch.optim as optim\n",
    "# from skorch import NeuralNetClassifier\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_space = [\n",
    "#     {\n",
    "#         \"solver\": \"lbfgs\",\n",
    "#         \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "#         \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "#         \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "#         \"max_iter\": [200, 500, 1000],\n",
    "#         \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "#         \"max_fun\": [10000, 15000],\n",
    "#     },\n",
    "#     {\n",
    "#         \"solver\": \"adam\",\n",
    "#         \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "#         \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "#         \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "#         \"max_iter\": [200, 500, 1000],\n",
    "#         \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "#         \"batch_size\": ['auto', n_samples // 5, n_samples // 10],\n",
    "#         \"learning_rate_init\": [0.0005, 0.001, 0.005],\n",
    "#         \"shuffle\": [False, True],\n",
    "#         \"early_stopping\": [False, True],\n",
    "#         \"validation_fraction\": [0.1, 0.15],\n",
    "#         \"n_iter_no_change\": [10, 15],\n",
    "#         # not sure abt these values, should we be changing these?\n",
    "#         \"beta_1\": [0.75, 0.9],\n",
    "#         \"beta_2\": [0.85, 0.999],\n",
    "#         \"epsilon\": [1e-07, 1e-08],\n",
    "#     },\n",
    "#     {\n",
    "#         \"solver\": \"sgd\",\n",
    "#         \"hidden_layer_sizes\": [(100,), (50, 50,), (50, 25, 25,)], # pick better ones\n",
    "#         \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "#         \"alpha\": [0.00001, 0.0001, 0.001],\n",
    "#         \"max_iter\": [200, 500, 1000],\n",
    "#         \"tol\": [0.0001, 0.001, 0.01, 0.1],\n",
    "#         \"batch_size\": ['auto', n_samples // 5, n_samples // 10],\n",
    "#         \"learning_rate_init\": [0.0005, 0.001, 0.005],\n",
    "#         \"shuffle\": [False, True],\n",
    "#         \"early_stopping\": [False, True],\n",
    "#         \"validation_fraction\": [0.1, 0.15],\n",
    "#         \"n_iter_no_change\": [10, 15],\n",
    "#         \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "#         \"momentum\": [0.75, 0.9],\n",
    "#         \"nesterovs_momentum\": [False, True],\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataLoader(object):\n",
    "#     def __init__(self, x, y, batch_size=128, shuffle=True):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "#         self.batch_size = batch_size\n",
    "#         self.shuffle = shuffle\n",
    "#         self.start_idx = 0\n",
    "#         self.data_size = x.shape[0]\n",
    "#         if self.shuffle:\n",
    "#             self.reset()\n",
    "    \n",
    "#     def reset(self):\n",
    "#         self.x, self.y = shuffle(self.x, self.y)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "    \n",
    "#     def __next__(self):\n",
    "#         if self.start_idx >= self.data_size:\n",
    "#             if self.shuffle:\n",
    "#                 self.reset()\n",
    "#             self.start_idx = 0\n",
    "#             raise StopIteration\n",
    "    \n",
    "#         batch_x = self.x[self.start_idx:self.start_idx+self.batch_size]\n",
    "#         batch_y = self.y[self.start_idx:self.start_idx+self.batch_size]\n",
    "\n",
    "#         batch_x = torch.tensor(batch_x, dtype=torch.float, device=device)\n",
    "#         batch_y = torch.tensor(batch_y, dtype=torch.float, device=device)\n",
    "\n",
    "#         self.start_idx += self.batch_size\n",
    "\n",
    "#         return (batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomMLPRegressor(nn.Module):\n",
    "#     def __init__(self, in_dim, hidden_layers=(50, 50), activation=nn.ReLU, dropout_rate=0.5, weight_constraint=1.0, weight_init=torch.nn.init.xavier_uniform_):\n",
    "#         super(MLP, self).__init__()\n",
    "        \n",
    "#         self.layers = []\n",
    "#         self.activation = activation()\n",
    "        \n",
    "#         assert(len(hidden_layers) > 0)\n",
    "        \n",
    "#         for i, count in enumerate(hidden_layers):\n",
    "#             if i == 0:\n",
    "#                 self.layers.append(nn.Linear(self.in_dim, count))\n",
    "#             if i == len(hidden_layers) - 1:\n",
    "#                 self.layers.append(nn.Linear(count, 1))\n",
    "#             elif i != 0 and i != len(hidden_layers) - 1:\n",
    "#                 self.layers.append(nn.Linear(hidden_layers[i - 1], count))\n",
    "#             weight_init(self.layers[-1].weight)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # maxnorm weight before actual forward pass\n",
    "#         with torch.no_grad():\n",
    "#             for layer in self.layers:\n",
    "#                 norm = layer.weight.norm(2, dim=0, keepdim=True).clamp(min=self.weight_constraint / 2)\n",
    "#                 desired = torch.clamp(norm, max=self.weight_constraint)\n",
    "#                 layer.weight *= (desired / norm)\n",
    "         \n",
    "#         for i, layer in enumerate(self.layers):\n",
    "#             if i == len(hidden_layers) - 1:\n",
    "#                 x = self.dropout(x)\n",
    "#             x = self.activation(layer(x))\n",
    "            \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
