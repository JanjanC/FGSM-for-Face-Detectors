{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from generate_perturbation import pipeline\n",
    "from extract_image_mask import create_mask\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorchyolo.models import load_model\n",
    "from minepsilon import yf_det_fn as yf_detect_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79edf5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(image):\n",
    "    return np.transpose(image.detach().cpu().squeeze().numpy(), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CHANGE THESE VARS\n",
    "IMG_PATH = r\"D:\\Users\\amosc\\Documents\\Coding\\Thesis\\THS-ST2\\THS-ST1\\images\\Test\\334935304_3512222965724455_1965518849144669583_n.jpg\"\n",
    "CHOSEN_COLOR_SPACE = \"LAB\" #TODO: <-- pick a colorspace\n",
    "CHOSEN_REGION = \"bbox\"  #TODO: <-- pick the region where the feature is extracted\n",
    "DETECTION_MODEL = 0 #0 yf, 1 mp, 2 yn\n",
    "PERTURB_REGION = 0 #0 - mask, 1 - bbox, 2-lbbox\n",
    "PRED_MODEL = 0 #0 mpr, 1 rfr, 2 svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2107d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_eps_path = [\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_face_yf.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_face_yf.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_face_yf.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_bbox_yf.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_bbox_yf.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_bbox_yf.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_lbbox_yf.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_lbbox_yf.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_lbbox_yf.pkl\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "mp_eps_path = [\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_face_mp.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_face_mp.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_face_mp.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_bbox_mp.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_bbox_mp.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_bbox_mp.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_lbbox_mp.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_lbbox_mp.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_lbbox_mp.pkl\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "yn_eps_path = [\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_face_yn.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_face_yn.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_face_yn.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_bbox_yn.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_bbox_yn.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_bbox_yn.pkl\"\n",
    "    ],\n",
    "    [\n",
    "        \"models/mpr_tunedfs_bo_LAB_bbox_e_lbbox_yn.pkl\",\n",
    "        \"models/rfr_tunedfs_bo_LAB_bbox_e_lbbox_yn.pkl\",\n",
    "        \"models/svr_tunedfs_bo_LAB_bbox_e_lbbox_yn.pkl\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "eps_path_list = [yf_eps_path, mp_eps_path, yn_eps_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f559a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "curr_eps_path = eps_path_list[DETECTION_MODEL][PERTURB_REGION][PRED_MODEL]\n",
    "eps_model = joblib.load(curr_eps_path)\n",
    "\n",
    "CSV_FILENAME = \"DROPPEDWITHATTRIBUTESNULL_recompiled_features_updated_yunet_pixels_bg_pixels_fixlbbox.csv\" #<-- update csv name\n",
    "df_features = pd.read_csv(CSV_FILENAME)\n",
    "train_set, test_set = train_test_split(df_features, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27672267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_mask(IMG_PATH)\n",
    "image = pipeline(IMG_PATH, eps_model, CHOSEN_COLOR_SPACE, CHOSEN_REGION, PERTURB_REGION)\n",
    "plt.imshow(tensor_to_image(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae625e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Can YOLO-face detect faces?:\", yf_detect_faces(image, return_boxes=False))\n",
    "print(\"Can MediaPipe detect faces?:\", mp_detect_faces(image, return_boxes=False))\n",
    "print(\"Can YuNet detect faces?:\", yn_detect_faces(image, return_boxes=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c970ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: load model here (edit this whole cell as necessary, idk paano magproperly load from joblib)\n",
    "# random_state = 100\n",
    "\n",
    "# import joblib\n",
    "# from sklearn.base import clone as clone_model\n",
    "\n",
    "# labels = {\"mask\": \"e_bbox_yf\", \"bbox\": \"e_face_yf\"}\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder = LabelEncoder()\n",
    "# categorical_columns = df_features.select_dtypes(include=[bool, object]).columns\n",
    "# encoded_columns = df_features[categorical_columns].apply(encoder.fit_transform)\n",
    "\n",
    "# df_encoded_features = df_features.copy()\n",
    "# df_encoded_features[categorical_columns] = encoded_columns\n",
    "\n",
    "# def get_features_and_label(color_space, region):\n",
    "#     features = [\"w\", \"h\", \"x\", \"y\"]\n",
    "#     for color_channel in color_channels[color_space]: \n",
    "#         features += [color_channel + region + \"_\" + str(i) for i in range(26)]\n",
    "#     features += [\"LBP_BIN_\" + region + \"_\" + str(i) for i in range(26)]\n",
    "#     features += [\"SOBELX_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "#     features += [\"SOBELY_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "#     features += [\"SOBEL_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "#     return features, labels[region]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# features, _ = get_features_and_label(CHOSEN_COLOR_SPACE, CHOSEN_REGION)\n",
    "# label = \"e_bbox_yf\"\n",
    "\n",
    "# X_features =  df_encoded_features.loc[:,  features]\n",
    "# y_features = df_encoded_features.loc[:, label].values #<-- pick label\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_features, y_features, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b7785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
