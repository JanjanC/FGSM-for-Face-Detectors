{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "cv_folds = 5\n",
    "\n",
    "if not os.path.isdir(\"model_dumps\"):\n",
    "    os.makedirs(\"model_dumps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to download our existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import download_weight\n",
    "download_weight(\"./min_epsilon_dataset.csv\", \"https://drive.google.com/uc?export=download&id=14qjnVqEqE0pqzsYsjuHIQCGW7emyVazu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains and saves the weights of IARM. To load new weights, create an instance of an IARM object and set the weight location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filename here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CSV_FILENAME = \"min_epsilon_dataset.csv\"\n",
    "df_features = pd.read_csv(CSV_FILENAME).head(35)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change string types to numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "categorical_columns = df_features.select_dtypes(include=[bool, object]).columns\n",
    "encoded_columns = df_features[categorical_columns].apply(encoder.fit_transform)\n",
    "encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_features = df_features.copy()\n",
    "df_encoded_features[categorical_columns] = encoded_columns\n",
    "df_encoded_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_regions = [\"bbox\", \"mask\"]\n",
    "non_color_features = [\"w\", \"h\", \"x\", \"y\", \"obj_score\", \"class_score\"]\n",
    "\n",
    "color_channels = {\n",
    "    \"RGB\": (\"R_BIN_\", \"G_BIN_\", \"B_BIN_\"),\n",
    "    \"HSV\": (\"H_HSV_BIN_\", \"S_HSV_BIN_\", \"V_HSV_BIN_\"),\n",
    "    \"HSL\": (\"H_HSL_BIN_\", \"S_HSL_BIN_\", \"L_HSL_BIN_\"),\n",
    "    \"LAB\": (\"L_LAB_BIN_\", \"A_LAB_BIN_\", \"B_LAB_BIN_\"),\n",
    "    \"YCBCR\": (\"Y_BIN_\", \"CR_BIN_\", \"CB_BIN_\"),\n",
    "}\n",
    "\n",
    "label_regions = [\"lbbox\", \"bbox\", \"face\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(color_space, region, label_model=\"yf\", label_region=None):\n",
    "    if label_region is None:\n",
    "        label_region = region if region != \"mask\" else \"face\"\n",
    "        \n",
    "    features = list(non_color_features)\n",
    "    for color_channel in color_channels[color_space]: \n",
    "        features += [color_channel + region + \"_\" + str(i) for i in range(26)]\n",
    "    features += [\"LBP_BIN_\" + region + \"_\" + str(i) for i in range(26)]\n",
    "    features += [\"SOBELX_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    features += [\"SOBELY_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    features += [\"SOBEL_BIN_\" + region + \"_\" + str(i) for i in range(20)]\n",
    "    \n",
    "    return features, \"e_\" + label_region + \"_\" + label_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predictions):\n",
    "    return np.sqrt(np.mean(np.square(predictions - actual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(actual, predictions):\n",
    "    return np.mean(np.abs(predictions - actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_error(actual, pred):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for a,b in zip(pred, actual):\n",
    "        if a > b:\n",
    "            total += a - b\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    return total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concealment_ratio(actual, pred):\n",
    "    count = 0\n",
    "    for a, b in zip(pred, actual):\n",
    "        if a >= b:\n",
    "            count+= 1\n",
    "            \n",
    "    return count / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(y_true, y_pred, penalty=1):\n",
    "    pmae = positive_error(y_true, y_pred)\n",
    "    concealment = concealment_ratio(y_true, y_pred)\n",
    "    \n",
    "    pmae_target = np.mean(y_train)\n",
    "    \n",
    "    pmae_norm = pmae / pmae_target\n",
    "    \n",
    "    return concealment - (pmae_norm * penalty)\n",
    "    \n",
    "concealment_scorer = make_scorer(custom_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and Hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_COLOR_SPACE = \"HSV\" #<-- pick a colorspace\n",
    "CHOSEN_REGION = \"bbox\" #lbbox next\n",
    "\n",
    "features, _ = get_features_and_label(CHOSEN_COLOR_SPACE, CHOSEN_REGION)\n",
    "label = \"e_face_yf\" #\"e_bbox_mp\"  #<-- pick label\n",
    "\n",
    "X_features =  df_encoded_features.loc[:,  features]\n",
    "y_features = df_encoded_features.loc[:, label].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_features, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.base import clone as clone_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_estimators\": Integer(100, 350),\n",
    "    \"criterion\": Categorical([\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]),\n",
    "    \"max_depth\": Integer(1, 300),\n",
    "    \"min_samples_split\": Integer(2, 32),\n",
    "    \"min_samples_leaf\": Integer(1, 20),\n",
    "    \"max_features\": Categorical([None, \"sqrt\", \"log2\", 0.25, 0.5, 0.75]),\n",
    "    \"max_leaf_nodes\": Integer(50, 300),\n",
    "    \"min_impurity_decrease\": Real(0.0, 2.0),\n",
    "    \"bootstrap\": Categorical([False, True]),\n",
    "    \"ccp_alpha\": Real(0.0, 2.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "bo_rfr = BayesSearchCV(rfr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_rfr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_rfr, \"model_dumps/rfr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', bo_rfr.best_params_)\n",
    "\n",
    "print('Test')\n",
    "y_pred = bo_rfr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print('Train')\n",
    "y_pred = bo_rfr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('rfr', rfr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"rfr__n_estimators\": Integer(100, 350),\n",
    "    \"rfr__criterion\": Categorical([\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]),\n",
    "    \"rfr__max_depth\": Integer(1, 300),\n",
    "    \"rfr__min_samples_split\": Integer(2, 32),\n",
    "    \"rfr__min_samples_leaf\": Integer(1, 20),\n",
    "    \"rfr__max_features\": Categorical([None, \"sqrt\", \"log2\", 0.25, 0.5, 0.75]),\n",
    "    \"rfr__max_leaf_nodes\": Integer(50, 300),\n",
    "    \"rfr__min_impurity_decrease\": Real(0.0, 2.0),\n",
    "    \"rfr__bootstrap\": Categorical([False, True]),\n",
    "    \"rfr__ccp_alpha\": Real(0.0, 2.0),\n",
    "}\n",
    "\n",
    "bo_rfr = BayesSearchCV(pipe, search_space, n_iter=75, n_jobs=-1, cv=cv_folds, random_state=random_state, scoring=concealment_scorer)\n",
    "bo_rfr.fit(X_train, y_train)\n",
    "joblib.dump(bo_rfr, \"model_dumps/rfr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_rfr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_rfr = clone_model(bo_rfr.best_estimator_)\n",
    "best_rfr.fit(X_train, y_train)\n",
    "joblib.dump(best_rfr, \"model_dumps/rfr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_rfr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_rfr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_rfr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"kernel\": Categorical([\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "    \"degree\": Integer(3, 20),\n",
    "    \"gamma\": Categorical([\"auto\", \"scale\"]),\n",
    "    \"coef0\": Real(0.0, 5.0),\n",
    "    \"tol\": Real(0.0001, 0.1),\n",
    "    \"C\": Real(0.0001, 1000.0),\n",
    "    \"epsilon\": Real(0.05, .5),\n",
    "    \"shrinking\": Categorical([False, True]),\n",
    "    \"max_iter\": Integer(100, 5000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "bo_svr = BayesSearchCV(svr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_svr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_svr, \"model_dumps/svr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', bo_svr.best_params_)\n",
    "\n",
    "print('Test')\n",
    "y_pred = bo_svr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print('Train')\n",
    "y_pred = bo_svr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('svr', svr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"svr__kernel\": Categorical([\"linear\", \"poly\", \"rbf\", \"sigmoid\"]),\n",
    "    \"svr__degree\": Integer(3, 20),\n",
    "    \"svr__gamma\": Categorical([\"auto\", \"scale\"]),\n",
    "    \"svr__coef0\": Real(0.0, 5.0),\n",
    "    \"svr__tol\": Real(0.0001, 0.1),\n",
    "    \"svr__C\": Real(0.0001, 1000.0),\n",
    "    \"svr__epsilon\": Real(0.05, .5),\n",
    "    \"svr__shrinking\": Categorical([False, True]),\n",
    "    \"svr__max_iter\": Integer(100, 5000),\n",
    "}\n",
    "\n",
    "bo_svr = BayesSearchCV(pipe, search_space, n_iter=75, n_jobs=-1, cv=cv_folds, random_state=random_state, scoring=concealment_scorer)\n",
    "bo_svr.fit(X_train, y_train)\n",
    "joblib.dump(bo_svr, \"model_dumps/svr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_svr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_svr = clone_model(bo_svr.best_estimator_)\n",
    "best_svr.fit(X_train, y_train)\n",
    "joblib.dump(best_svr, \"model_dumps/svr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_svr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_svr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_svr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization With No Custom Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sz = X_train.shape[1] * 2 // 3 + 1\n",
    "search_space = {\n",
    "    \"activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"alpha\": Real(0.00001, 0.001),\n",
    "    \"learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"max_iter\": Integer(200, 1000),\n",
    "    \"tol\": Real(0.0001, 0.1),\n",
    "    \"momentum\": Real(0.75, 0.9),\n",
    "    \"nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"early_stopping\": Categorical([False, True]),\n",
    "    \"validation_fraction\": Real(0.1, 0.15),\n",
    "    \"beta_1\": Real(0.75, 0.9),\n",
    "    \"beta_2\": Real(0.85, 0.999),\n",
    "    \"epsilon\": Real(1e-08, 1e-07),\n",
    "    \"max_fun\": Integer(10000, 15000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concealment_scorer = make_scorer(custom_scorer, greater_is_better=True, penalty=1.1578947368421053)\n",
    "mpr = MLPRegressor(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "bo_mpr = BayesSearchCV(mpr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_mpr, \"model_dumps/no_custom_loss\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', bo_mpr.best_params_)\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = bo_mpr.predict(X_test)\n",
    "print(\"RMSE\", rmse(y_test, y_pred))\n",
    "print(\"MAE\", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = bo_mpr.predict(X_train)\n",
    "print(\"RMSE\", rmse(y_train, y_pred))\n",
    "print(\"MAE\", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpr = MLPRegressor(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('mpr', mpr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"mpr__activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"mpr__solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"mpr__alpha\": Real(0.00001, 0.001),\n",
    "    \"mpr__learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"mpr__learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"mpr__max_iter\": Integer(200, 1000),\n",
    "    \"mpr__tol\": Real(0.0001, 0.1),\n",
    "    \"mpr__momentum\": Real(0.75, 0.9),\n",
    "    \"mpr__nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"mpr__early_stopping\": Categorical([False, True]),\n",
    "    \"mpr__validation_fraction\": Real(0.1, 0.15),\n",
    "    \"mpr__beta_1\": Real(0.75, 0.9),\n",
    "    \"mpr__beta_2\": Real(0.85, 0.999),\n",
    "    \"mpr__epsilon\": Real(1e-08, 1e-07),\n",
    "    \"mpr__max_fun\": Integer(10000, 15000),\n",
    "}\n",
    "\n",
    "bo_mpr = BayesSearchCV(pipe, search_space, n_iter=76, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "joblib.dump(bo_mpr, \"model_dumps/no_custom_loss_bo_fs\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_mpr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_mpr = clone_model(bo_mpr.best_estimator_)\n",
    "best_mpr.fit(X_train, y_train)\n",
    "joblib.dump(best_mpr, \"model_dumps/no_custom_loss_fs\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_mpr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_mpr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_mpr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bayesian Optimization With Custom Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sz = X_train.shape[1] * 2 // 3 + 1\n",
    "search_space = {\n",
    "    \"activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"alpha\": Real(0.00001, 0.001),\n",
    "    \"learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"max_iter\": Integer(200, 1000),\n",
    "    \"tol\": Real(0.0001, 0.1),\n",
    "    \"momentum\": Real(0.75, 0.9),\n",
    "    \"nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"early_stopping\": Categorical([False, True]),\n",
    "    \"validation_fraction\": Real(0.1, 0.15),\n",
    "    \"beta_1\": Real(0.75, 0.9),\n",
    "    \"beta_2\": Real(0.85, 0.999),\n",
    "    \"epsilon\": Real(1e-08, 1e-07),\n",
    "    \"max_fun\": Integer(10000, 15000),\n",
    "    \"loss_alpha\": Integer(0, 1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred, alpha=2):\n",
    "    squared_error_sum = 0\n",
    "    for a, b in zip(y_true, y_pred):\n",
    "        if b < a: #underpredict\n",
    "            squared_error_sum += ((a - b) ** 2 ) * alpha #penalize\n",
    "        else: #overpredict or just right\n",
    "            squared_error_sum += ((a - b) ** 2 )\n",
    "    \n",
    "    mse = squared_error_sum / len(y_true)\n",
    "    \n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network._base import DERIVATIVES\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "class CustomMLP(MLPRegressor):\n",
    "    def __init__(self, loss_alpha=2, hidden_layer_sizes=(100,), activation=\"relu\", *, solver=\"adam\", alpha=0.0001, batch_size=\"auto\", learning_rate=\"constant\", learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=1e-4, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-8, n_iter_no_change=10, max_fun=15000):\n",
    "        super().__init__(\n",
    "            hidden_layer_sizes=hidden_layer_sizes,\n",
    "            activation=activation,\n",
    "            solver=solver,\n",
    "            alpha=alpha,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            learning_rate_init=learning_rate_init,\n",
    "            power_t=power_t,\n",
    "            max_iter=max_iter,\n",
    "            shuffle=shuffle,\n",
    "            random_state=random_state,\n",
    "            tol=tol,\n",
    "            verbose=verbose,\n",
    "            warm_start=warm_start,\n",
    "            momentum=momentum,\n",
    "            nesterovs_momentum=nesterovs_momentum,\n",
    "            early_stopping=early_stopping,\n",
    "            validation_fraction=validation_fraction,\n",
    "            beta_1=beta_1,\n",
    "            beta_2=beta_2,\n",
    "            epsilon=epsilon,\n",
    "            n_iter_no_change=n_iter_no_change,\n",
    "            max_fun=max_fun,\n",
    "        )\n",
    "        self.loss_alpha = loss_alpha\n",
    "    \n",
    "    def _backprop(self, X, y, activations, deltas, coef_grads, intercept_grads):\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        # Forward propagate\n",
    "        activations = self._forward_pass(activations)\n",
    "\n",
    "        # Get loss\n",
    "        loss_func_name = \"custom_loss\"\n",
    "        loss = custom_loss(y, activations[-1], alpha=self.loss_alpha)\n",
    "        \"\"\"\n",
    "        loss_func_name = self.loss\n",
    "        if loss_func_name == \"log_loss\" and self.out_activation_ == \"logistic\":\n",
    "            loss_func_name = \"binary_log_loss\"\n",
    "        loss = LOSS_FUNCTIONS[loss_func_name](y, activations[-1])\n",
    "        \"\"\"\n",
    "        # Add L2 regularization term to loss\n",
    "        values = 0\n",
    "        for s in self.coefs_:\n",
    "            s = s.ravel()\n",
    "            values += np.dot(s, s)\n",
    "        loss += (0.5 * self.alpha) * values / n_samples\n",
    "\n",
    "        # Backward propagate\n",
    "        last = self.n_layers_ - 2\n",
    "\n",
    "        # The calculation of delta[last] here works with following\n",
    "        # combinations of output activation and loss function:\n",
    "        # sigmoid and binary cross entropy, softmax and categorical cross\n",
    "        # entropy, and identity with squared loss\n",
    "        deltas[last] = activations[-1] - y\n",
    "\n",
    "        # Compute gradient for the last layer\n",
    "        self._compute_loss_grad(\n",
    "            last, n_samples, activations, deltas, coef_grads, intercept_grads\n",
    "        )\n",
    "\n",
    "        inplace_derivative = DERIVATIVES[self.activation]\n",
    "        # Iterate over the hidden layers\n",
    "        for i in range(self.n_layers_ - 2, 0, -1):\n",
    "            deltas[i - 1] = safe_sparse_dot(deltas[i], self.coefs_[i].T)\n",
    "            inplace_derivative(activations[i], deltas[i - 1])\n",
    "\n",
    "            self._compute_loss_grad(\n",
    "                i - 1, n_samples, activations, deltas, coef_grads, intercept_grads\n",
    "            )\n",
    "\n",
    "        return loss, coef_grads, intercept_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpr = CustomMLP(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "bo_mpr = BayesSearchCV(mpr, search_space, n_iter=50, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(bo_mpr, \"model_dumps/mpr_tuned_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Best parameters found:\\n', bo_mpr.best_params_)\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = bo_mpr.predict(X_test)\n",
    "print(\"RMSE\", rmse(y_test, y_pred))\n",
    "print(\"MAE\", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = bo_mpr.predict(X_train)\n",
    "print(\"RMSE\", rmse(y_train, y_pred))\n",
    "print(\"MAE\", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Concealment Ratio\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpr = CustomMLP(random_state=random_state, hidden_layer_sizes=(hidden_sz, hidden_sz * 2 // 3))\n",
    "pipe = Pipeline([('selector', SelectKBest(f_regression)), ('mpr', mpr)])\n",
    "\n",
    "search_space = {\n",
    "    \"selector__k\": Integer(X_train.shape[1] // 2, X_train.shape[1] - 1),\n",
    "    \"mpr__activation\": Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"]),\n",
    "    \"mpr__solver\": Categorical([\"lbfgs\", \"adam\", \"sgd\"]),\n",
    "    \"mpr__alpha\": Real(0.00001, 0.001),\n",
    "    \"mpr__learning_rate\": Categorical([\"constant\", \"invscaling\", \"adaptive\"]),\n",
    "    \"mpr__learning_rate_init\": Real(0.0005, 0.005),\n",
    "    \"mpr__max_iter\": Integer(200, 1000),\n",
    "    \"mpr__tol\": Real(0.0001, 0.1),\n",
    "    \"mpr__momentum\": Real(0.75, 0.9),\n",
    "    \"mpr__nesterovs_momentum\": Categorical([False, True]),\n",
    "    \"mpr__early_stopping\": Categorical([False, True]),\n",
    "    \"mpr__validation_fraction\": Real(0.1, 0.15),\n",
    "    \"mpr__beta_1\": Real(0.75, 0.9),\n",
    "    \"mpr__beta_2\": Real(0.85, 0.999),\n",
    "    \"mpr__epsilon\": Real(1e-08, 1e-07),\n",
    "    \"mpr__max_fun\": Integer(10000, 15000),\n",
    "    \"mpr__loss_alpha\": Integer(0, 1000),\n",
    "}\n",
    "\n",
    "bo_mpr = BayesSearchCV(pipe, search_space, n_iter=76, n_jobs=-1, cv=cv_folds, random_state=random_state, verbose=2, scoring=concealment_scorer)\n",
    "bo_mpr.fit(X_train, y_train)\n",
    "joblib.dump(bo_mpr, \"model_dumps/mpr_tunedfs_bo_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") \n",
    "\n",
    "selected_feat = bo_mpr.best_estimator_.named_steps[\"selector\"].get_support()\n",
    "best_mpr = clone_model(bo_mpr.best_estimator_)\n",
    "best_mpr.fit(X_train, y_train)\n",
    "joblib.dump(best_mpr, \"model_dumps/mpr_tunedfs_\" + CHOSEN_COLOR_SPACE + \"_\" + CHOSEN_REGION + \"_\" + label + \".pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params:\\n', bo_mpr.best_params_)\n",
    "print('Best features found:\\n', X_train.columns[selected_feat])\n",
    "\n",
    "print(\"Test\")\n",
    "y_pred = best_mpr.predict(X_test)\n",
    "print(\"RMSE: \", rmse(y_test, y_pred))\n",
    "print(\"MAE: \", mae(y_test, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_test, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_test, y_pred))\n",
    "\n",
    "print(\"Train\")\n",
    "y_pred = best_mpr.predict(X_train)\n",
    "print(\"RMSE: \", rmse(y_train, y_pred))\n",
    "print(\"MAE: \", mae(y_train, y_pred))\n",
    "print(\"Positive Error\", positive_error(y_train, y_pred))\n",
    "print(\"Face Percent\", concealment_ratio(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
